# agent.py
from dotenv import load_dotenv
import os

# Load .env from backend directory regardless of execution context
# This ensures consistent environment loading whether called directly or via API
backend_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))  # Get backend directory
env_path = os.path.join(backend_dir, '.env')
load_dotenv(env_path)

# Variables d'environnement
import os

# Variables et donn√©es
import json
from typing import TypedDict, List, Annotated, Any
import pandas as pd
from io import StringIO
import textwrap

# Graphiques
import plotly.express as px
import plotly.io as pio
import plotly.graph_objects as go
import graphviz

# Num√©ro de session unique
import uuid

# Import de scripts
from src.fetch_data import APILimitError 
from src.chart_theme import stella_theme 

# LangGraph et LangChain
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, ToolMessage, SystemMessage
from langgraph.graph import StateGraph, END
from langgraph.graph.message import AnyMessage, add_messages
from langgraph.checkpoint.memory import MemorySaver
from langsmith import Client

# Configuration HTTP pour √©viter les timeouts apr√®s inactivit√©
import httpx
from datetime import timedelta

# Note: Proxy configuration removed as we're now using OpenRouter directly


# --- Import des tools ---
from tools import (
    available_tools,
    _fetch_recent_news_logic,
    _search_ticker_logic,
    _fetch_data_logic, 
    _preprocess_data_logic, 
    _analyze_risks_logic, 
    _create_dynamic_chart_logic,
    _fetch_profile_logic,
    _fetch_price_history_logic,
    _compare_fundamental_metrics_logic,
    _compare_price_histories_logic
    # _query_research_document_logic imported lazily in execute_tool_node
)

# Environment variables and constants
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
OPENROUTER_MODEL = "google/gemini-2.5-flash-lite"  # GLM-4.5-Air model via OpenRouter
LANGSMITH_TRACING = True
LANGSMITH_ENDPOINT = "https://api.smith.langchain.com"
LANGSMITH_API_KEY = os.getenv("LANGSMITH_API_KEY")
LANGSMITH_PROJECT = os.environ.get("LANGCHAIN_PROJECT", "stella")

if not OPENROUTER_API_KEY:
    raise ValueError("OPENROUTER_API_KEY n'a pas √©t√© enregistr√©e comme variable d'environnement.")

# Configure httpx client avec des timeouts robustes pour √©viter les blocages
# Probl√®me r√©solu : apr√®s inactivit√©, les connexions TCP vers OpenRouter deviennent stale
httpx_client = httpx.Client(
    timeout=httpx.Timeout(
        connect=10.0,    # Timeout pour √©tablir la connexion
        read=120.0,      # Timeout pour lire la r√©ponse (important pour les LLMs)
        write=10.0,      # Timeout pour envoyer la requ√™te
        pool=5.0         # Timeout pour obtenir une connexion du pool
    ),
    limits=httpx.Limits(
        max_connections=10,
        max_keepalive_connections=5,
        keepalive_expiry=60.0  # Expire les connexions keep-alive apr√®s 60s
    ),
    headers={
        "User-Agent": "Stella-Agent/1.0",
        "Connection": "close"  # Force la fermeture des connexions apr√®s chaque requ√™te
    }
)

# Initialize the LLM with OpenRouter avec client httpx configur√©
llm = ChatOpenAI(
    model=OPENROUTER_MODEL,
    api_key=OPENROUTER_API_KEY,
    base_url="https://openrouter.ai/api/v1",
    temperature=0,
    streaming=True,  # Enable streaming
    http_client=httpx_client,  # Utilise notre client configur√©
    request_timeout=120,        # Timeout global de 2 minutes
    max_retries=2,              # Retry en cas de timeout
)
print(f"‚úÖ ChatOpenAI initialized with OpenRouter using model: {OPENROUTER_MODEL}")
print(f"üîß HTTP client configured with robust timeouts to prevent post-inactivity hangs")

# Objet AgentState pour stocker et modifier l'√©tat de l'agent entre les n≈ìuds
class AgentState(TypedDict):
    input: str
    ticker: str
    tickers: List[str]
    company_name: str
    fetched_df_json: str
    processed_df_json: str
    analysis: str
    plotly_json: str  
    messages: Annotated[List[AnyMessage], add_messages]
    error: str

# --- Prompt syst√®me (d√©finition du r√¥le de l'agent) ---
system_prompt = """Ton nom est Stella. Tu es une assistante experte financi√®re. Ton but principal est d'aider les utilisateurs en analysant des actions. Tu as √©t√© cr√©√©e par une √©quipe de recherche dans le cadre du **Projet OPA**.

Lien du repo Github du projet :
https://github.com/DataScientest-Studio/nov24_cds_opa
  
**Structure des r√©ponses**
Tu r√©pondras toujours de mani√®re structur√©e et claire, en utilisant des balises strong, puces, etc en markdown pour organiser l'information.

** TU DOIS TOUJOURS TERMINER TA REPONSE APR√àS AVOIR APPEL√â UN OUTIL OU UNE SEQUENCE d'OUTILS.**

**R√®gle d'Or : Le Contexte est Roi**
Tu DOIS toujours prendre en compte les messages pr√©c√©dents pour comprendre la demande actuelle. 
Si un utilisateur demande de modifier ou d'ajouter quelque chose, tu dois te baser sur l'analyse ou le graphique qui vient d'√™tre montr√©. 
Ne recommence jamais une analyse de z√©ro si ce n'est pas explicitement demand√©.

**Gestion des Demandes Hors Sujet (Tr√®s Important !)**
Ton domaine d'expertise est STRICTEMENT l'analyse financi√®re des actions.
Si un utilisateur te pose une question qui n'est pas li√©e √† l'analyse d'actions, √† la finance, aux entreprises ou √† tes propres capacit√©s (par exemple : "Montre moi le cours de l'or", "Analyse le bitcoin", "raconte-moi une blague", "quelle est la capitale de la France ?", "donne-moi une recette de cuisine"), tu ne DOIS PAS utiliser d'outils.
Dans ce cas, tu dois r√©pondre directement et poliment que ce n'est pas dans ton domaine de comp√©tence, et rappeler ce que tu peux faire.

**Capacit√©s et Limites des Donn√©es (Information Cruciale)**
Tu dois imp√©rativement comprendre et respecter ces deux r√®gles :
1.  **Analyse Fondamentale (m√©triques comme ROE, dette, revenus) :** Cette analyse est **UNIQUEMENT DISPONIBLE POUR LES ACTIONS AM√âRICAINES** (cot√©es sur le NYSE, NASDAQ, etc.). Si on te demande une analyse fondamentale sur une action europ√©enne ou asiatique (ex: LVMH, Samsung, Cr√©dit Agricole), tu dois poliment d√©cliner en expliquant que cette fonctionnalit√© est limit√©e aux actions am√©ricaines, mais que tu peux tout de m√™me afficher son cours de bourse.
2.  **Analyse du Cours de Bourse (prix de l'action) :** Cette analyse est **DISPONIBLE POUR LES MARCH√âS MONDIAUX** (Europe, Asie, Am√©riques). Tu peux afficher et comparer les graphiques de prix pour n'importe quelle action, √† condition d'avoir le bon ticker (ex: `AIR.PA` pour Airbus, `005930.KS` pour Samsung).

**Liste des outils disponibles**
1.  `search_ticker`: Recherche le ticker boursier d'une entreprise √† partir de son nom. **√Ä UTILISER EN DERNIER RECOURS UNIQUEMENT** si tu ne connais vraiment pas le ticker d'une entreprise connue.
2.  `fetch_data`: R√©cup√®re les donn√©es financi√®res fondamentales pour un ticker. **RAPPEL : Ne fonctionne que pour les actions am√©ricaines.**
3.  `preprocess_data`: Pr√©pare et nettoie les donn√©es financi√®res. **RAPPEL : Ne fonctionne que sur les donn√©es am√©ricaines.**
4.  `analyze_risks`: Pr√©dit la performance d'une action. **RAPPEL : Ne fonctionne que sur les donn√©es am√©ricaines.**
5.  `display_price_chart`: Affiche un graphique de l'√©volution du prix (cours) d'une action. **Fonctionne pour les actions du monde entier.**
6.  `display_raw_data`: Affiche les donn√©es financi√®res brutes. **RAPPEL : Donn√©es am√©ricaines uniquement.**
7.  `display_processed_data`: Affiche les donn√©es financi√®res trait√©es. **RAPPEL : Donn√©es am√©ricaines uniquement.**
8.  `create_dynamic_chart`: Cr√©e un graphique interactif sur les donn√©es fondamentales. **RAPPEL : Donn√©es am√©ricaines uniquement.**
9.  `get_stock_news`: R√©cup√®re les derni√®res actualit√©s. **Fonctionne mieux pour les entreprises internationales.**
10. `get_company_profile`: R√©cup√®re le profil d'une entreprise. **Fonctionne pour les entreprises internationales.**
11. `compare_stocks`: Compare plusieurs entreprises sur une m√©trique financi√®re ou sur leur prix. **Lis attentivement les instructions ci-dessous pour cet outil.**
12. `query_research`: Recherche dans le rapport de projet via un syst√®me RAG pour trouver, expliquer ou r√©sumer des informations li√©es au contexte et √† la recherche du projet.

**Formatage des appels d'outils**
Tu dois toujours appeler les outils avec les arguments n√©cessaires, en respectant la structure suivante :

{
  "name": "fetch_data",
  "arguments": {"ticker": "TSLA"}
}
Utilise bien un formatage JSON et pas de XML sinon ta r√©ponse sera rejet√©e. Ajout TOUJOURS un texte d'explication d'une ou deux phrases de ton raisonnement avant l'appel de l'outil, pour expliquer pourquoi tu l'appelles.

Si l'utilisateur te demande √† quoi tu sers, ce que tu sais faire, ou toute autre demande similaire, tu n'utiliseras **AUCUN OUTIL**.
Tu expliqueras clairement, et de mani√®re exhaustive tes fonctionnalit√©s, et en donnant des exemples.
---

**S√©quence d'analyse compl√®te (Actions Am√©ricaines Uniquement)**
Quand un utilisateur te demande une analyse compl√®te, tu DOIS appeler TOUS les outils n√©cessaires EN UNE SEULE FOIS. :
1.  `search_ticker` UNIQUEMENT si tu ne connais vraiment pas le ticker d'une entreprise bien connue.
2.  `fetch_data` avec le ticker (que tu connais directement ou que tu as trouv√©).
3.  `preprocess_data` pour nettoyer les donn√©es.
4.  `analyze_risks` pour obtenir un verdict.

**IMPORTANT : Pour une analyse compl√®te, tu dois faire PLUSIEURS appels d'outils dans la m√™me r√©ponse.** Par exemple, si l'utilisateur demande "Analyse AAPL", tu dois appeler fetch_data, preprocess_data ET analyze_risks dans la m√™me r√©ponse, sans attendre de retour entre chaque outil.

Ta t√¢che est consid√©r√©e comme termin√©e apr√®s l'appel √† `analyze_risks`. La r√©ponse finale avec le graphique sera g√©n√©r√©e automatiquement.
Exemples de demandes devant d√©clencher une analyse compl√®te : 
* "Analyse Tesla"
* "Tu peux m'analyser Apple"
* "Quels risques d'investissement pour McDonald's ?"

**IDENTIFICATION DU TICKER - R√àGLE STRICTE** 
**TU CONNAIS D√âJ√Ä LES TICKERS DES ENTREPRISES PRINCIPALES :**
- Apple = AAPL, Microsoft = MSFT, Google/Alphabet = GOOGL, Amazon = AMZN, Tesla = TSLA, Meta = META
- Netflix = NFLX, Nvidia = NVDA, Coca-Cola = KO, McDonald's = MCD, Disney = DIS, Nike = NKE
- Bank of America = BAC, JPMorgan = JPM, Goldman Sachs = GS, American Express = AXP
- Boeing = BA, General Electric = GE, Ford = F, General Motors = GM
- Et TOUTES les entreprises du Fortune 500 et les grandes entreprises internationales

**UTILISE DIRECTEMENT les tickers que tu connais.** N'utilise `search_ticker` QUE pour des entreprises vraiment obscures ou r√©gionales que tu ne connais pas du tout.

**Actions europ√©ennes courantes :**
- ASML = ASML, LVMH = MC.PA, Airbus = AIR.PA, L'Or√©al = OR.PA, Sanofi = SAN.PA
- Nestl√© = NESN.SW, TSMC = TSM, Samsung = 005930.KS

**Analyse et Visualisation Dynamique (Actions Am√©ricaines Uniquement) :**
Quand un utilisateur te demande de "montrer", "visualiser" des m√©triques sp√©cifiques (par exemple, "montre-moi l'√©volution du ROE"), tu DOIS appeler TOUS les outils n√©cessaires EN UNE SEULE FOIS :
1.  Appelle `fetch_data`.
2.  Appelle `preprocess_data`.
3.  Appelle `create_dynamic_chart`.

**IMPORTANT : Tu dois faire ces TROIS appels d'outils dans la m√™me r√©ponse**, sans attendre de retour entre chaque outil.

**Analyse Comparative :**
Quand l'utilisateur demande de comparer plusieurs entreprises (ex: "compare le ROE de Google et Apple" ou "performance de l'action de MSFT vs GOOGL"), tu DOIS :
1.  **Identifier le type de comparaison :**
    *   Si la m√©trique est 'price' (prix, cours, performance de l'action), c'est une **comparaison de PRIX**. Elle fonctionne pour TOUTES les actions.
    *   Si la m√©trique est fondamentale (ROE, dette, marketCap, etc.), c'est une **comparaison FONDAMENTALE**. Elle ne fonctionne que pour les actions AM√âRICAINES. Si l'une des actions n'est pas am√©ricaine, tu dois refuser la comparaison et expliquer pourquoi, en proposant de comparer leur prix √† la place.
2.  Si les tickers ne sont pas donn√©s, utilise directement les tickers des entreprises connues. N'utilise `search_ticker` QUE pour des entreprises vraiment inconnues.
3.  Utilise l'outil `compare_stocks` en cons√©quence :
    *   Pour une comparaison **fondamentale** (am√©ricaine uniquement) : `comparison_type='fundamental'`, `metric='roe'` (par exemple).
    *   Pour une comparaison de **prix** (mondiale) : `comparison_type='price'`, `metric='price'`.

**AFFICHAGE DE DONNEES** 
Si l'utilisateur te demande d'afficher des donn√©es, tu dois appeler TOUS les outils n√©cessaires EN UNE SEULE FOIS :
* V√©rifier si l'entreprise est am√©ricaine ou internationale. R√©pondre en rappelant tes limites si l'entreprise n'est pas am√©ricaine. 
* Si des donn√©es ne sont pas disponibles dans le contexte, tu dois appeler `fetch_data` ET ENSUITE `display_raw_data` ou `display_processed_data` dans la m√™me r√©ponse.
* Si des donn√©es sont d√©j√† disponibles, appelle directement l'outil d'affichage appropri√©.

**IMPORTANT : Pour afficher des donn√©es trait√©es, tu dois faire fetch_data, preprocess_data ET display_processed_data dans la m√™me r√©ponse** si les donn√©es ne sont pas d√©j√† disponibles.

Tu dois bien comprendre que tu ne dois jamais afficher les donn√©es brutes ou trait√©es sans utiliser ces outils, car ils formatent correctement les donn√©es pour l'affichage.
Exemples : 
* "Affiche les donn√©es brutes de Tesla" -> `fetch_data` + `display_raw_data` (en une fois)
* "Affiche les donn√©es trait√©es d'Apple" -> `fetch_data` + `preprocess_data` + `display_processed_data` (en une fois)
* "Montre-moi les donn√©es" -> `display_raw_data` (si donn√©es d√©j√† disponibles)
* "Tableau des donn√©es" -> `display_raw_data` (si donn√©es d√©j√† disponibles)

**DEMANDES LIEES AU PROJET OPA**
Tu as acc√®s au document de recherche interne l'√©quipe qui t'a cr√©√©e via l'outil `query_research`.
Ton but est d'essayer de r√©pondre au maximum √† des questions qui pourraient √™tre en lien avec le projet OPA, ou avec ta cr√©ation.
Lorsqu'une question est pos√©e sur le projet (cr√©ateurs, fonctionnement, m√©thodologie, conclusion, ta stack technique, etc), tu DOIS TOUJOURS utiliser l'outil `query_research` pour obtenir des informations pertinentes.
Le contexte seul ne suffit pas, car il n'est pas toujours √† jour ou complet. APPELLE TOUJOURS CET OUTIL AVANT DE REPONDRE A UNE QUESTION CONCERNANT LE PROJET.
Utilise cet outil quand l'utilisateur:
* De mani√®re g√©n√©ral, pose n'importe quelle question concernant le contexte du projet.
* Demande comment tu as √©t√© cr√©√©e.
* Pose des questions sur les m√©thodologies, analyses ou conclusions de recherche de l'√©quipe, ou toute autre information concernant le projet dans lequel tu as √©t√© cr√©√©e.

**Gestion des Questions de Suivi (Tr√®s Important !)**

**TU DOIS TOUJOURS UTILISER DES TOOL CALLS POUR LES DEMANDES DE SUIVI !** Ne r√©ponds jamais par du texte seul si l'utilisateur demande d'ajouter, modifier ou analyser quelque chose.

*   **Si je montre un graphique et que l'utilisateur dit "ajoute Meta", "et pour [nouveau ticker] ?" ou "rajoute [ticker]"**: Tu DOIS appeler `compare_stocks` avec la liste des tickers pr√©c√©dents PLUS le nouveau ticker.
    *Ex: Apr√®s un graphique de `['AAPL', 'GOOG']`, si l'utilisateur dit "ajoute Meta", tu DOIS appeler `compare_stocks(tickers=['AAPL', 'GOOG', 'META'], metric='price', comparison_type='price')`.*

*   **Si l'utilisateur demande d'analyser une nouvelle action apr√®s en avoir analys√© une autre**: Tu DOIS faire une nouvelle analyse compl√®te avec les outils appropri√©s (`fetch_data`, `preprocess_data`, `analyze_risks`).
    *Ex: Apr√®s "analyse Tesla", si l'utilisateur dit "analyse Apple", tu DOIS appeler tous les outils n√©cessaires pour Apple.*

*   **Si l'utilisateur demande de changer la p√©riode**: Tu DOIS refaire le dernier graphique avec la nouvelle p√©riode.
    *Ex: Apr√®s un graphique sur 1 an, si l'utilisateur dit "montre sur 5 ans", tu DOIS rappeler le m√™me outil avec `period_days=1260`.*

*   **Pour le NASDAQ 100**: Utilise le ticker de l'ETF `QQQ`. Pour le S&P 500, utilise `SPY`. Si l'utilisateur mentionne un indice, ajoute son ticker √† la liste pour la comparaison de prix.

**R√àGLE CRUCIALE POUR LES DEMANDES DE SUIVI :**
Si l'utilisateur fait une demande qui n√©cessite des donn√©es ou des outils (ajouter un ticker, faire une nouvelle analyse, changer une p√©riode, etc.), tu DOIS TOUJOURS utiliser les tool calls appropri√©s. Ne fournis JAMAIS une r√©ponse textuelle seule pour ces demandes.

Lorsuqe tu √©cris un ticker ou ton nom Stella, entoure le toujours de backticks (``) pour le mettre en valeur. (ex: `AAPL`).
Tu dois toujours r√©pondre en fran√ßais, tutoyer ton interlocuteur, adopter un ton joyeux, ajoute toujours une pointe d'humour dans tes messages.
Fais TOUJOURS r√©f√©rence √† **Stella comme toi m√™me**. 
Fais attention au formatage de tes r√©ponses, √† toujours bien placer des balises markdown, afin de structurer tes r√©ponses et les rendre agr√©ables √† lire.
"""

# --- D√©finition des noeuds du Graph ---

# Noeud 1 : agent_node, point d'entr√©e et appel du LLM 
def agent_node(state: AgentState):
    """Le 'cerveau' de l'agent. D√©cide du prochain outil √† appeler."""
    print("\n--- AGENT: D√©cision de la prochaine √©tape... ---")

    # On commence par le prompt syst√®me pour donner le r√¥le
    current_messages = [SystemMessage(content=system_prompt)]
    
    # --- INJECTION DE CONTEXTE DYNAMIQUE ---
    context_parts = []
    
    # Contexte des donn√©es disponibles
    data_to_inspect_json = state.get("processed_df_json") or state.get("fetched_df_json")
    if data_to_inspect_json:
        try:
            df = pd.read_json(StringIO(data_to_inspect_json), orient='split')
            available_columns = df.columns.tolist()
            context_parts.append(f"Des donn√©es sont disponibles avec les colonnes : {available_columns}")
        except Exception as e:
            print(f"Avertissement: Impossible d'injecter le contexte des colonnes. Erreur: {e}")
    
    # Contexte des tickers dans une comparaison en cours
    current_tickers = state.get("tickers")
    if current_tickers and len(current_tickers) > 1:
        context_parts.append(f"COMPARAISON EN COURS : {current_tickers}")
        
        # D√©terminer le type de comparaison bas√© sur le dernier message d'outil
        last_tool_call = None
        for msg in reversed(state['messages']):
            if isinstance(msg, AIMessage) and msg.tool_calls:
                for tool_call in msg.tool_calls:
                    if tool_call['name'] == 'compare_stocks':
                        last_tool_call = tool_call
                        break
                if last_tool_call:
                    break
        
        if last_tool_call:
            comparison_type = last_tool_call['args'].get('comparison_type', 'price')
            metric = last_tool_call['args'].get('metric', 'price')
            period_days = last_tool_call['args'].get('period_days', 252)
            
            context_parts.append(f"Type de comparaison actuelle : {comparison_type}")
            context_parts.append(f"M√©trique compar√©e : {metric}")
            if comparison_type == 'price':
                context_parts.append(f"P√©riode : {period_days} jours")
            
            context_parts.append(f"""R√àGLES POUR LES DEMANDES DE SUIVI :
- Si l'utilisateur dit "ajoute [ticker]" ou "rajoute [ticker]" : utilise compare_stocks avec tickers={current_tickers + ['NOUVEAU_TICKER']}, metric='{metric}', comparison_type='{comparison_type}'
- Si l'utilisateur change la p√©riode : utilise compare_stocks avec les m√™mes tickers et metric='{metric}', comparison_type='{comparison_type}', mais p√©riode diff√©rente
- Si l'utilisateur change la m√©trique : utilise compare_stocks avec les m√™mes tickers mais nouvelle m√©trique et bon comparison_type""")
    
    # Contexte du ticker principal pour analyses individuelles
    current_ticker = state.get("ticker")
    if current_ticker and not current_tickers:
        context_parts.append(f"ANALYSE INDIVIDUELLE EN COURS : {current_ticker}")
        context_parts.append(f"Si l'utilisateur demande d'analyser un nouveau ticker, tu DOIS faire une nouvelle analyse compl√®te avec fetch_data, preprocess_data, analyze_risks.")
    
    if context_parts:
        context_message = SystemMessage(
            content=(
                f"\n\n--- CONTEXTE ACTUEL ---\n"
                + "\n".join(context_parts) +
                f"\n---------------------------------\n"
            )
        )
        current_messages.append(context_message)

    # On ajoute l'historique de la conversation depuis l'√©tat
    current_messages.extend(state['messages'])

    # üïê TIMING: Start measuring LLM inference time
    import time
    llm_start_time = time.time()
    print(f"‚è±Ô∏è  [LLM] Starting inference call to {OPENROUTER_MODEL}...")
    
    # On invoque le LLM avec la liste de messages compl√®te
    # Cette liste est locale et ne modifie pas l'√©tat directement
    response = llm.bind_tools(available_tools).invoke(current_messages)
    
    # üïê TIMING: End measuring LLM inference time
    llm_end_time = time.time()
    llm_duration = llm_end_time - llm_start_time
    print(f"‚è±Ô∏è  [LLM] Inference completed in {llm_duration:.2f} seconds")
    
    print(f"response.content: {response.content}")
    return {"messages": [response]}

# Noeud 2 : execute_tool_node, ex√©cute les outils en se basant sur la d√©cision de l'agent_node (Noeud 1).
def execute_tool_node(state: AgentState):
    """Le "pont" qui ex√©cute la logique r√©elle et met √† jour l'√©tat."""
    print("\n--- OUTILS: Ex√©cution d'un outil ---")
    action_message = next((msg for msg in reversed(state['messages']) if isinstance(msg, AIMessage) and msg.tool_calls), None)
    if not action_message:
        raise ValueError("Aucun appel d'outil trouv√© dans le dernier AIMessage.")

    tool_outputs = []
    current_state_updates = {}
    
    # Create a working copy of state that gets updated as we execute tools
    working_state = state.copy()
    
    # On g√®re le cas o√π plusieurs outils sont appel√©s, bien que ce soit rare ici.
    for tool_call in action_message.tool_calls:
        tool_name = tool_call['name']
        tool_args = tool_call['args']
        tool_id = tool_call['id']
        print(f"Le LLM a d√©cid√© d'appeler le tool : {tool_name} - avec les arguments : {tool_args}")
        
        # üïê TIMING: Start measuring tool execution time
        import time
        tool_start_time = time.time()
        print(f"‚è±Ô∏è  [TOOL] Starting execution of '{tool_name}'...")

        try:
            if tool_name == "search_ticker":
                company_name = tool_args.get("company_name")
                ticker = _search_ticker_logic(company_name=company_name)
                # On stocke le ticker ET le nom de l'entreprise
                current_state_updates["ticker"] = ticker
                current_state_updates["company_name"] = company_name 
                tool_outputs.append(ToolMessage(tool_call_id=tool_id, content=f"[Ticker `{ticker}` trouv√©.]"))

            elif tool_name == "fetch_data":
                try:
                    output_df = _fetch_data_logic(ticker=tool_args.get("ticker"))
                    current_state_updates["fetched_df_json"] = output_df.to_json(orient='split')
                    current_state_updates["ticker"] = tool_args.get("ticker")
                    # Update working state immediately for next tool
                    working_state["fetched_df_json"] = current_state_updates["fetched_df_json"]
                    working_state["ticker"] = current_state_updates["ticker"]
                    tool_outputs.append(ToolMessage(tool_call_id=tool_id, content="[Donn√©es r√©cup√©r√©es avec succ√®s.]"))
                except APILimitError as e:
                    user_friendly_error = "D√©sol√©, il semble que j'aie un probl√®me d'acc√®s √† mon fournisseur de donn√©es. Peux-tu r√©essayer plus tard ?"
                    tool_outputs.append(ToolMessage(tool_call_id=tool_id, content=json.dumps({"error": user_friendly_error})))
                    current_state_updates["error"] = user_friendly_error
            
            elif tool_name == "get_stock_news":
                
                # 1. On cherche le ticker dans les arguments fournis par le LLM, SINON dans l'√©tat.
                ticker = tool_args.get("ticker") or state.get("ticker")
                
                # 2. Si apr√®s tout √ßa, on n'a toujours pas de ticker, c'est une vraie erreur.
                if not ticker:
                    raise ValueError("Impossible de d√©terminer un ticker pour chercher les nouvelles, ni dans la commande, ni dans le contexte.")
                
                # 3. On fait pareil pour le nom de l'entreprise (qui est optionnel mais utile)
                # On utilise le ticker comme nom si on n'a rien d'autre.
                company_name = tool_args.get("company_name") or state.get("company_name") or ticker
                
                # 4. On appelle la logique avec les bonnes informations.
                news_summary = _fetch_recent_news_logic(
                    ticker=ticker, 
                    company_name=company_name
                )

                tool_outputs.append(ToolMessage(tool_call_id=tool_id, content=news_summary))
                
            elif tool_name == "preprocess_data":
                # Check working state first, then fall back to original state
                fetched_df_json = current_state_updates.get("fetched_df_json") or working_state.get("fetched_df_json")
                if not fetched_df_json:
                    raise ValueError("Impossible de pr√©traiter les donn√©es car elles n'ont pas encore √©t√© r√©cup√©r√©es.")
                fetched_df = pd.read_json(StringIO(fetched_df_json), orient='split')
                output = _preprocess_data_logic(df=fetched_df)
                current_state_updates["processed_df_json"] = output.to_json(orient='split')
                # Update working state immediately for next tool
                working_state["processed_df_json"] = current_state_updates["processed_df_json"]
                tool_outputs.append(ToolMessage(tool_call_id=tool_id, content="[Donn√©es pr√©trait√©es avec succ√®s.]"))

            elif tool_name == "analyze_risks":
                # Check working state first, then fall back to original state  
                processed_df_json = current_state_updates.get("processed_df_json") or working_state.get("processed_df_json")
                if not processed_df_json:
                    raise ValueError("Impossible de faire une pr√©diction car les donn√©es n'ont pas encore √©t√© pr√©trait√©es.")
                processed_df = pd.read_json(StringIO(processed_df_json), orient='split')
                output = _analyze_risks_logic(processed_data=processed_df)
                current_state_updates["analysis"] = output
                # Update working state immediately for potential next tool
                working_state["analysis"] = current_state_updates["analysis"]
                tool_outputs.append(ToolMessage(tool_call_id=tool_id, content=output))
            
            elif tool_name == "create_dynamic_chart":
                # Check working state first for data access in tool chains
                data_json_for_chart = (
                    current_state_updates.get("processed_df_json") or 
                    working_state.get("processed_df_json") or 
                    current_state_updates.get("fetched_df_json") or 
                    working_state.get("fetched_df_json")
                )
                if not data_json_for_chart:
                    raise ValueError("Aucune donn√©e disponible pour cr√©er un graphique.")
                
                # On convertit le JSON en DataFrame
                df_for_chart = pd.read_json(StringIO(data_json_for_chart), orient='split')
                
                chart_json = _create_dynamic_chart_logic(
                    data=df_for_chart,  # <--- Le DataFrame est pass√© directement
                    chart_type=tool_args.get('chart_type'),
                    x_column=tool_args.get('x_column'),
                    y_column=tool_args.get('y_column'),
                    title=tool_args.get('title'),
                    color_column=tool_args.get('color_column')
                )
                
                
                if "Erreur" in chart_json:
                    raise ValueError(chart_json) # Transforme l'erreur de l'outil en exception
                
                current_state_updates["plotly_json"] = chart_json
                tool_outputs.append(ToolMessage(tool_call_id=tool_id, content="[Graphique interactif cr√©√©.]"))

            elif tool_name in ["display_raw_data", "display_processed_data"]:
                # V√©rifie la disponibilit√© des donn√©es en tenant compte de la cha√Æne d'outils en cours
                if tool_name == "display_raw_data":
                    df_json = (
                        current_state_updates.get("fetched_df_json") or
                        working_state.get("fetched_df_json") or
                        state.get("fetched_df_json")
                    )
                else:  # display_processed_data
                    df_json = (
                        current_state_updates.get("processed_df_json") or
                        working_state.get("processed_df_json") or
                        state.get("processed_df_json")
                    )

                if not df_json:
                    raise ValueError("Aucune donn√©e disponible √† afficher.")

                # Rien √† renvoyer ici, on laisse le noeud prepare_data_display attacher le bon DataFrame
                tool_outputs.append(ToolMessage(tool_call_id=tool_id, content="[Pr√©paration de l'affichage des donn√©es.]"))

            elif tool_name == "get_company_profile":
                ticker = tool_args.get("ticker")
                profile_json = _fetch_profile_logic(ticker=ticker)
                tool_outputs.append(ToolMessage(tool_call_id=tool_id, content=profile_json))
            
            elif tool_name == "display_price_chart":
                ticker = tool_args.get("ticker")
                period = tool_args.get("period_days", 252) # Utilise la valeur par d√©faut si non fournie
                
                # On appelle notre logique pour r√©cup√©rer les donn√©es de prix
                price_df = _fetch_price_history_logic(ticker=ticker, period_days=period)
                
                # On cr√©e le graphique directement ici
                fig = px.line(
                    price_df, 
                    x=price_df.index, 
                    y='close', 
                    title=f"Historique du cours de `{ticker.upper()}` sur {period} jours",
                    color_discrete_sequence=stella_theme['colors']

                )
                fig.update_layout(
                    template=stella_theme['template'], 
                    font=stella_theme['font'], 
                    xaxis_title="Date", 
                    yaxis_title="Prix de cl√¥ture (USD)",
                    xaxis=stella_theme['axis_config'],
                    yaxis=stella_theme['axis_config'],
                    legend=dict(
                        bordercolor="rgba(0, 0, 0, 0)",  # Pas de bordure
                        borderwidth=0
                    )
                )
                
                # On convertit en JSON et on met √† jour l'√©tat
                chart_json = pio.to_json(fig)
                current_state_updates["plotly_json"] = chart_json
                tool_outputs.append(ToolMessage(tool_call_id=tool_id, content="[Graphique de prix cr√©√© avec succ√®s.]"))

            elif tool_name == "compare_stocks":
                tickers = tool_args.get("tickers")
                metric = tool_args.get("metric")
                comparison_type = tool_args.get("comparison_type", "fundamental")

                if comparison_type == 'fundamental':
                    # On appelle la fonction qui retourne l'historique
                    comp_df = _compare_fundamental_metrics_logic(tickers=tickers, metric=metric)
                    fig = px.line(
                        comp_df,
                        x=comp_df.index,
                        y=comp_df.columns,
                        title=f"√âvolution de la m√©trique '{metric.upper()}'",
                        labels={'value': metric.upper(), 'variable': 'Ticker', 'calendarYear': 'Ann√©e'},
                        markers=True, # Les marqueurs sont utiles pour voir les points de donn√©es annuels
                        color_discrete_sequence=stella_theme['colors']  # Utilise la palette de couleurs Stella
                    )
                elif comparison_type == 'price':
                    # La logique pour le prix ne change pas, elle est d√©j√† une √©volution
                    period = tool_args.get("period_days", 252)
                    comp_df = _compare_price_histories_logic(tickers=tickers, period_days=period)
                    fig = px.line(
                        comp_df,
                        title=f"Comparaison de la performance des actions (Base 100)",
                        labels={'value': 'Performance Normalis√©e (Base 100)', 'variable': 'Ticker', 'index': 'Date'},
                        color_discrete_sequence=stella_theme['colors']
                    )
                else:
                    raise ValueError(f"Type de comparaison inconnu: {comparison_type}")

                # Le reste du code est commun et ne change pas
                fig.update_layout(
                    template="plotly_white",
                    xaxis=stella_theme['axis_config'],
                    yaxis=stella_theme['axis_config'],
                    legend=dict(
                        bordercolor="rgba(0, 0, 0, 0)",  # Pas de bordure
                        borderwidth=0
                    )
                )
                chart_json = pio.to_json(fig)
                current_state_updates["plotly_json"] = chart_json
                current_state_updates["tickers"] = tickers
                tool_outputs.append(ToolMessage(tool_call_id=tool_id, content="[Graphique de comparaison cr√©√©.]"))
            
            elif tool_name == "query_research":
                query = tool_args.get("query")
                # Lazy import to avoid initialization delays
                from src.pdf_research import query_research_document as _query_research_document_logic
                research_result = _query_research_document_logic(query=query)
                tool_outputs.append(ToolMessage(tool_call_id=tool_id, content=research_result))
            
        except Exception as e:
            # Bloc de capture g√©n√©rique pour toutes les autres erreurs
            error_msg = f"Erreur lors de l'ex√©cution de l'outil '{tool_name}': {repr(e)}"
            tool_outputs.append(ToolMessage(tool_call_id=tool_id, content=f"[ERREUR: {error_msg}]"))
            current_state_updates["error"] = error_msg
            print(error_msg)
        
        # üïê TIMING: End measuring tool execution time
        tool_end_time = time.time()
        tool_duration = tool_end_time - tool_start_time
        print(f"‚è±Ô∏è  [TOOL] '{tool_name}' completed in {tool_duration:.2f} seconds")
            
    current_state_updates["messages"] = tool_outputs
    return current_state_updates

# Noeud 3 : generate_final_response_node, synth√©tise la r√©ponse finale √† partir de l'√©tat.
def generate_final_response_node(state: AgentState):
    """
    G√©n√®re la r√©ponse textuelle finale ET le graphique Plotly par d√©faut apr√®s une analyse compl√®te.
    Ce noeud est le point de sortie pour une analyse de pr√©diction.
    """
    print("\n--- AGENT: G√©n√©ration de la r√©ponse finale et du graphique ---")
    
    # --- 1. R√©cup√©ration des informations de l'√©tat ---
    ticker = state.get("ticker", "l'action")
    analysis_result = state.get("analysis", "inconnu")
    processed_df_json = state.get("processed_df_json")

    # --- 2. Construction de la r√©ponse textuelle ---
    response_content = ""
    latest_year_str = "r√©centes"
    next_year_str = "prochaine"
    
    if processed_df_json:
        try:
            df = pd.read_json(StringIO(processed_df_json), orient='split')
            if not df.empty and 'calendarYear' in df.columns:
                latest_year_str = df['calendarYear'].iloc[-1]
                next_year_str = str(int(latest_year_str) + 1)
        except Exception as e:
            print(f"Avertissement : Impossible d'extraire l'ann√©e des donn√©es : {e}")

    # Logique de la r√©ponse textuelle bas√©e sur la pr√©diction
    if analysis_result == "Risque √âlev√© D√©tect√©":
        response_content = (
            f"‚ö†Ô∏è **Attention !** Pour l'action `{ticker.upper()}`, en se basant sur les donn√©es de `{latest_year_str}`(derni√®res donn√©es disponibles), mon analyse a d√©tect√© des signaux indiquant un **risque √©lev√© de sous-performance pour l'ann√©e √† venir (`{next_year_str}`)**.\n\n"
            "Mon mod√®le est particuli√®rement confiant dans cette √©valuation. Je te conseille la plus grande prudence."
        )
    elif analysis_result == "Aucun Risque Extr√™me D√©tect√©":
        response_content = (
            f"Pour l'action `{ticker.upper()}`, en se basant sur les donn√©es de `{latest_year_str}`(derni√®res donn√©es disponibles), mon analyse n'a **pas d√©tect√© de signaux de danger extr√™me pour l'ann√©e √† venir (`{next_year_str}`)**.\n\n"
            "**Important :** Cela ne signifie pas que c'est un bon investissement. Cela veut simplement dire que mon mod√®le, sp√©cialis√© dans la d√©tection de signaux tr√®s n√©gatifs, n'en a pas trouv√© ici. Mon r√¥le est de t'aider √† √©viter une erreur √©vidente, pas de te garantir un succ√®s."
        )
    else:
        response_content = f"L'analyse des donn√©es pour `{ticker.upper()}` a √©t√© effectu√©e, mais le r√©sultat de la pr√©diction n'a pas pu √™tre interpr√©t√©."

    # --- 3. Cr√©ation du graphique de synth√®se ---
    chart_json = None
    explanation_text = None 
    if processed_df_json:
        try:
            df = pd.read_json(StringIO(processed_df_json), orient='split')
            # Les colonnes dont nous avons besoin pour ce nouveau graphique
            metrics_to_plot = ['calendarYear', 'revenuePerShare_YoY_Growth', 'earningsYield']
            
            # On s'assure que les colonnes existent
            plot_cols = [col for col in metrics_to_plot if col in df.columns]
            
            if not df.empty and all(col in plot_cols for col in metrics_to_plot):
                chart_title = f"Analyse Croissance vs. Valorisation pour {ticker.upper()}"
                
                # Cr√©er la figure de base
                fig = go.Figure()

                # 1. Ajouter les barres de Croissance du CA (% YoY) sur l'axe Y1
                fig.add_trace(go.Scatter(
                    x=df['calendarYear'],
                    y=df['revenuePerShare_YoY_Growth'],
                    name='Croissance (%)',
                    mode='lines+markers', # On sp√©cifie le mode ligne avec marqueurs
                    line=dict(color=stella_theme['colors'][1]), # On utilise 'line' pour la couleur
                    yaxis='y1'
                ))

                # 2. Ajouter la ligne de Valorisation (Earnings Yield) sur l'axe Y2
                fig.add_trace(go.Scatter(
                    x=df['calendarYear'],
                    y=df['earningsYield'],
                    name='Valorisation',
                    mode='lines+markers',
                    line=dict(color=stella_theme['colors'][0]), # Bleu Stella
                    yaxis='y2'
                ))
                
                # Ajouter une ligne √† z√©ro pour mieux visualiser la croissance positive/n√©gative
                fig.add_hline(y=0, line_width=1, line_dash="dash", line_color="black", yref="y1")

                # 3. Configurer les axes et le layout
                fig.update_layout(
                    title_text=chart_title,
                    template=stella_theme['template'],
                    font=stella_theme['font'],
                    **stella_theme['layout_defaults'],  # Applique les param√®tres glassmorphism
                    margin=dict(r=320),
                    xaxis=dict(
                        title='Ann√©e',
                        type='category', # Force l'axe √† traiter les ann√©es comme des √©tiquettes uniques
                        **stella_theme['axis_config']  # Applique la configuration d'axes noirs
                    ),
                    yaxis=dict(
                        title=dict(
                            text='Croissance Annuelle du CA',
                            font=dict(color=stella_theme['colors'][1])
                        ),
                        tickfont=dict(color=stella_theme['colors'][1]),
                        ticksuffix=' %',
                        **stella_theme['axis_config']  # Applique la configuration d'axes noirs
                    ),
                    yaxis2=dict(
                        title=dict(
                            text='Rendement b√©n√©ficiaire',
                            font=dict(color=stella_theme['colors'][0]) 
                        ),
                        tickfont=dict(color=stella_theme['colors'][0]),
                        anchor='x',
                        overlaying='y',
                        side='right',
                        tickformat='.2%',
                        **stella_theme['axis_config']  # Applique la configuration d'axes noirs
                    ),
                    legend=dict(
                        orientation="v",
                        yanchor="top",
                        y=1, # On aligne le haut de la l√©gende avec le haut du graphique
                        xanchor="left",
                        x=1.40, # On pousse la l√©gende un peu plus √† droite
                        bordercolor="rgba(0, 0, 0, 0)", # Pas de bordure
                        borderwidth=0,
                        title_text="L√©gende"
                    )
                )
                
                chart_json = pio.to_json(fig)
                response_content += f"\n\n**Voici une visualisation de sa croissance par rapport √† sa valorisation :**"
            else:
                response_content += "\n\n(Impossible de g√©n√©rer le graphique de synth√®se Croissance/Valorisation : donn√©es ou colonnes manquantes)."

        except Exception as e:
            print(f"Erreur lors de la cr√©ation du graphique par d√©faut : {e}")
            response_content += "\n\n(Je n'ai pas pu g√©n√©rer le graphique associ√© en raison d'une erreur.)"
    
    # --- 4. Cr√©ation du message final ---
    final_message = AIMessage(content=response_content)
    if chart_json:
        # On attache le graphique au message
        setattr(final_message, 'plotly_json', chart_json)

    return {"messages": [final_message]}

# Noeud 4 : cleanup_state_node, nettoie l'√©tat pour √©viter de stocker des donn√©es lourdes.
def cleanup_state_node(state: AgentState):
    """
    Nettoie l'√©tat pour la prochaine interaction.
    Il efface les donn√©es sp√©cifiques √† la derni√®re r√©ponse (pr√©diction, graphique)
    mais GARDE le contexte principal (donn√©es brutes et trait√©es, ticker)
    pour permettre des questions de suivi.
    """
    print("\n--- SYSTEM: Nettoyage partiel de l'√©tat avant la sauvegarde ---")
    
    # On garde : 'ticker', 'tickers', 'company_name', 'fetched_df_json', 'processed_df_json'
    # On supprime (r√©initialise) :
    return {
        "analysis": "",   # Efface la pr√©diction pr√©c√©dente
        "plotly_json": "",  # Efface le graphique pr√©c√©dent
        "error": ""         # Efface toute erreur pr√©c√©dente
    }

# Noeuds suppl√©mentaires de pr√©paration pour l'affichage des donn√©es, graphiques, actualit√©s et profil d'entreprise.
def prepare_data_display_node(state: AgentState):
    """Pr√©pare un AIMessage avec un DataFrame sp√©cifique attach√©."""
    print("\n--- AGENT: Pr√©paration du DataFrame pour l'affichage ---")
    
    tool_name_called = next(msg for msg in reversed(state['messages']) if isinstance(msg, AIMessage) and msg.tool_calls).tool_calls[-1]['name']

    if tool_name_called == "display_processed_data" and state.get("processed_df_json"):
        df_json = state["processed_df_json"]
        message_content = "Voici les donn√©es **pr√©-trait√©es** que tu as demand√©es :"
    elif tool_name_called == "display_raw_data" and state.get("fetched_df_json"):
        df_json = state["fetched_df_json"]
        message_content = "Voici les donn√©es **brutes** que tu as demand√©es :"
    else:
        final_message = AIMessage(content="D√©sol√©, les donn√©es demand√©es ne sont pas disponibles.")
        return {"messages": [final_message]}

    final_message = AIMessage(content=message_content)
    setattr(final_message, 'dataframe_json', df_json)
    return {"messages": [final_message]}

def prepare_chart_display_node(state: AgentState):
    """Pr√©pare un AIMessage avec le graphique Plotly demand√© par l'utilisateur."""
    print("\n--- AGENT: Pr√©paration du graphique pour l'affichage ---")
    
    # Laisse le LLM g√©n√©rer une courte phrase d'introduction
    response = ("**Voici le graphique demand√© :** ")
    
    final_message = AIMessage(content=response)
    setattr(final_message, 'plotly_json', state["plotly_json"])
    
    return {"messages": [final_message]}

def prepare_news_display_node(state: AgentState):
    """Pr√©pare un AIMessage avec les actualit√©s format√©es pour l'affichage."""
    print("\n--- AGENT: Pr√©paration de l'affichage des actualit√©s ---")
    
    # 1. Retrouver le ToolMessage qui contient le r√©sultat des actualit√©s
    # On cherche le dernier message de type ToolMessage dans l'historique
    tool_message = next((msg for msg in reversed(state['messages']) if isinstance(msg, ToolMessage)), None)
    
    if not tool_message or not tool_message.content:
        final_message = AIMessage(content="D√©sol√©, je n'ai pas pu r√©cup√©rer les actualit√©s.")
        return {"messages": [final_message]}

    # 2. Pr√©parer le contenu textuel de la r√©ponse
    ticker = state.get("ticker", "l'entreprise")
    company_name = state.get("company_name", ticker)
    
    # √âviter la duplication si company_name et ticker sont identiques ou si on utilise les valeurs par d√©faut
    if company_name.lower() == ticker.lower() or ticker == "l'entreprise":
        response_content = f"**Voici les derni√®res actualit√©s que j'ai trouv√©es pour {company_name.title()}** :"
    else:
        response_content = f"**Voici les derni√®res actualit√©s que j'ai trouv√©es pour {company_name.title()} ({ticker.upper()})** :"
    
    final_message = AIMessage(content=response_content)
    
    # 3. Attacher le JSON des actualit√©s au message final
    # Le front-end (Streamlit) utilisera cet attribut pour afficher les articles
    setattr(final_message, 'news_json', tool_message.content)
    
    return {"messages": [final_message]}

def prepare_profile_display_node(state: AgentState):
    """Pr√©pare un AIMessage avec le profil de l'entreprise pour l'affichage."""
    print("\n--- AGENT: Pr√©paration de l'affichage du profil d'entreprise ---")
    
    tool_message = next((msg for msg in reversed(state['messages']) if isinstance(msg, ToolMessage)), None)
    
    if not tool_message or not tool_message.content:
        final_message = AIMessage(content="D√©sol√©, je n'ai pas pu r√©cup√©rer le profil de l'entreprise.")
        return {"messages": [final_message]}

    prompt = f"""
    Voici les informations de profil pour une entreprise au format JSON :
    {tool_message.content}
    **INFORMATION CRUCIALE :**
    TU DOIS r√©diger une r√©ponse format√©e en markdown pour pr√©senter ces informations √† l'utilisateur.
    R√©dige une r√©ponse la plus exhaustive et agr√©able possible pour pr√©senter ces informations √† l'utilisateur.
    Mets en avant le nom de l'entreprise, son secteur et son CEO, mais n'omet aucune information qui n'est pas null dans le JSON.
    Tu n'afficheras pas l'image du logo, l'UI s'en chargera, et tu n'as pas besoin de la mentionner.
    Pr√©sente les informations de mani√®re sobre en listant les points du JSON.
    Si il y a un champ null, TU DOIS TOUJOURS le compl√©ter via tes connaissances, sans inventer de donn√©es.
    Si tu ne trouves pas d'informations, indique simplement "Inconnu" ou "Non disponible".
    Termine en donnant le lien vers leur site web.
    """
    response = llm.invoke(prompt)
    print(f"response.content: {response.content}")
    final_message = AIMessage(content=response.content)
    
    # On attache le JSON pour que le front-end puisse afficher l'image du logo !
    setattr(final_message, 'profile_json', tool_message.content)
    
    return {"messages": [final_message]}

# Noeud de gestion des erreurs
def handle_error_node(state: AgentState):
    """
    G√©n√®re un message d'erreur clair pour l'utilisateur, puis pr√©pare le nettoyage de l'√©tat.
    Ce noeud est appel√© par le routeur chaque fois que le champ 'error' est rempli.
    """
    print("\n--- AGENT: Gestion de l'erreur... ---")
    error_message = state.get("error", "Une erreur inconnue est survenue.")
    
    # On cr√©e une r√©ponse claire et format√©e pour l'utilisateur.
    user_facing_error = textwrap.dedent(f"""
        D√©sol√©, une erreur est survenue et je n'ai pas pu terminer ta demande.
        
        **D√©tail de l'erreur :**
        ```
        {error_message}
        ```
        
        Peux-tu essayer de reformuler ta question ou tenter une autre action ?
    """)
    
    # On met cette r√©ponse dans un AIMessage qui sera affich√© dans le chat.
    # L'√©tape suivante sera le nettoyage de l'√©tat.
    return {"messages": [AIMessage(content=user_facing_error)]}

# --- Router pour diriger le flux du graph ---
def router(state: AgentState) -> str:
    """Le routeur principal du graphe, version finale robuste avec support du tool chaining."""
    print("\n--- ROUTEUR: √âvaluation de l'√©tat pour choisir la prochaine √©tape ---")

    # On r√©cup√®re les messages de l'√©tat
    messages = state['messages']
    
    # Y a-t-il une erreur ? C'est la priorit√© absolue.
    if state.get("error"):
        print("Routeur -> D√©cision: Erreur d√©tect√©e, passage au gestionnaire d'erreurs.")
        return "handle_error"

    # Le dernier message est-il une d√©cision de l'IA d'appeler un outil ?
    last_message = messages[-1]

    if isinstance(last_message, AIMessage) and not last_message.tool_calls:
        print("Routeur -> D√©cision: L'IA a fourni une r√©ponse textuelle. Fin du cycle.")
        return END
    if isinstance(last_message, AIMessage) and last_message.tool_calls:
        # C'est la premi√®re fois qu'on voit cette d√©cision, on doit ex√©cuter l'outil.
        print("Routeur -> D√©cision: Appel d'outil demand√©, passage √† execute_tool.")
        return "execute_tool"

    # Si le dernier message n'est PAS un appel √† un outil, cela signifie probablement
    # qu'un outil vient de s'ex√©cuter. Nous devons d√©cider o√π aller ensuite.
    
    # On retrouve le dernier appel √† un outil fait par l'IA
    ai_message_with_tool_call = next(
        (msg for msg in reversed(messages) if isinstance(msg, AIMessage) and msg.tool_calls),
        None
    )
    # S'il n'y en a pas, on ne peut rien faire de plus.
    if not ai_message_with_tool_call:
        print("Routeur -> D√©cision: Aucune action claire √† prendre (pas d'appel d'outil trouv√©), fin du processus.")
        return END
    
    # Check if there are multiple tool calls to execute in sequence
    remaining_tool_calls = ai_message_with_tool_call.tool_calls
    executed_tool_calls = [msg for msg in reversed(messages) if isinstance(msg, ToolMessage)]
    
    print(f"--- ROUTEUR: Nombre total d'outils √† ex√©cuter: {len(remaining_tool_calls)}, d√©j√† ex√©cut√©s: {len(executed_tool_calls)}")
    
    # If we still have tools to execute from the same AI message, continue executing them
    if len(executed_tool_calls) < len(remaining_tool_calls):
        next_tool_name = remaining_tool_calls[len(executed_tool_calls)]['name']
        print(f"Routeur -> D√©cision: Outil suivant dans la cha√Æne: '{next_tool_name}', continuer l'ex√©cution.")
        return "execute_tool"
        
    # All tools from the current AI message have been executed, check the last executed tool
    tool_name = ai_message_with_tool_call.tool_calls[-1]['name']
    print(f"--- ROUTEUR: Tous les outils de la cha√Æne ont √©t√© ex√©cut√©s, le dernier √©tait '{tool_name}'. ---")

    # Maintenant, on d√©cide de la suite en fonction du dernier outil de la cha√Æne.
    if tool_name == 'analyze_risks':
        return "generate_final_response"
    elif tool_name == 'compare_stocks': 
        return "prepare_chart_display"
    elif tool_name == 'display_price_chart':
        return "prepare_chart_display"
    elif tool_name in ['display_raw_data', 'display_processed_data']:
        return "prepare_data_display"
    elif tool_name == 'create_dynamic_chart':
        return "prepare_chart_display"
    elif tool_name == 'get_stock_news':
        return "prepare_news_display"
    elif tool_name == 'get_company_profile': 
        return "prepare_profile_display"
    else: # Pour search_ticker, fetch_data, preprocess_data, etc
        return "agent"
    
# --- CONSTRUCTION DU GRAPH ---
def get_agent_app():
    memory = MemorySaver()
    workflow = StateGraph(AgentState)

    workflow.add_node("agent", agent_node)
    workflow.add_node("execute_tool", execute_tool_node)
    workflow.add_node("generate_final_response", generate_final_response_node)
    workflow.add_node("cleanup_state", cleanup_state_node)
    workflow.add_node("prepare_data_display", prepare_data_display_node) 
    workflow.add_node("prepare_chart_display", prepare_chart_display_node)
    workflow.add_node("prepare_news_display", prepare_news_display_node)
    workflow.add_node("prepare_profile_display", prepare_profile_display_node)
    workflow.add_node("handle_error", handle_error_node)

    workflow.set_entry_point("agent")

    workflow.add_conditional_edges("agent", router, {"execute_tool": "execute_tool", "handle_error": "handle_error", "__end__": END})
    workflow.add_conditional_edges(
        "execute_tool",
        router,
        {
            "agent": "agent", 
            "generate_final_response": "generate_final_response",
            "prepare_data_display": "prepare_data_display", 
            "prepare_chart_display": "prepare_chart_display",
            "prepare_news_display": "prepare_news_display", 
            "prepare_profile_display": "prepare_profile_display",
            "handle_error": "handle_error",
            "__end__": END
        }
    )

    workflow.add_edge("generate_final_response", "cleanup_state")
    workflow.add_edge("prepare_profile_display", "cleanup_state")
    workflow.add_edge("prepare_data_display", "cleanup_state")
    workflow.add_edge("prepare_chart_display", "cleanup_state")
    workflow.add_edge("prepare_news_display", "cleanup_state")
    workflow.add_edge("handle_error", "cleanup_state")
    workflow.add_edge("cleanup_state", END)

    app = workflow.compile(checkpointer=memory)

    try:
        graph = app.get_graph()
        image_bytes = graph.draw_mermaid_png()
        with open("agent_workflow.png", "wb") as f:
            f.write(image_bytes)
        
        print("\nVisualisation du graph sauvegard√©e dans le r√©pertoire en tant que agent_workflow.png \n")

    except Exception as e:
        print(f"\nJe n'ai pas pu g√©n√©rer la visualisation. Lancez 'pip install playwright' et 'playwright install'. Erreur: {e}\n")
    
    return app

app = get_agent_app()


# --- Cr√©e une animation du workflow ---
def get_langsmith_trace_data(thread_id: str):
    """
    R√©cup√®re les donn√©es de trace LangSmith pour la visualisation du graphique.
    Retourne les donn√©es structur√©es sans g√©n√©ration d'images.
    """
    print(f"\n{'='*80}")
    print(f"üîç LANGSMITH TRACE DEBUG - Starting trace retrieval for: {thread_id}")
    print(f"{'='*80}")
    
    # STEP 1: Environment and configuration check
    print(f"\nüìã STEP 1: Environment Configuration Check")
    print(f"   LANGCHAIN_PROJECT: {os.environ.get('LANGCHAIN_PROJECT', '‚ùå NOT_SET')}")
    print(f"   LANGSMITH_API_KEY: {'‚úÖ SET' if os.environ.get('LANGSMITH_API_KEY') else '‚ùå NOT_SET'}")
    print(f"   LANGCHAIN_TRACING_V2: {os.environ.get('LANGCHAIN_TRACING_V2', '‚ùå NOT_SET')}")
    print(f"   LANGCHAIN_ENDPOINT: {os.environ.get('LANGCHAIN_ENDPOINT', '‚ùå NOT_SET')}")
    
    # Check if tracing is enabled
    if os.environ.get('LANGCHAIN_TRACING_V2') != 'true':
        print(f"   ‚ö†Ô∏è  WARNING: LANGCHAIN_TRACING_V2 is not set to 'true'")
        print(f"   This means LangSmith tracing might not be active!")
    
    try:
        # STEP 2: Initialize LangSmith client
        print(f"\nüîß STEP 2: Initializing LangSmith Client")
        try:
            from langsmith import Client
            client = Client()
            print(f"   ‚úÖ LangSmith client initialized successfully")
            
            # Test client connection
            try:
                # Try to get client info to test connection
                print(f"   üîó Testing client connection...")
                client_info = client.info
                print(f"   ‚úÖ Client connection test successful")
            except Exception as conn_test_error:
                print(f"   ‚ö†Ô∏è  Client connection test failed: {conn_test_error}")
                print(f"   This might indicate API key or network issues")
                
        except ImportError as import_error:
            print(f"   ‚ùå Failed to import LangSmith Client: {import_error}")
            raise import_error
        except Exception as client_error:
            print(f"   ‚ùå Failed to initialize LangSmith client: {client_error}")
            raise client_error
        
        # STEP 3: Query runs with timeout protection
        print(f"\nüîç STEP 3: Querying LangSmith Runs")
        print(f"   Thread ID: {thread_id}")
        print(f"   Project: {os.environ.get('LANGCHAIN_PROJECT', 'stella')}")
        
        # Note: Removed signal-based timeout as it doesn't work in threads
        # The API endpoint already has asyncio timeout protection
        
        all_runs = []
        try:
            print(f"   üì° Sending query to LangSmith API...")
            
            # Try different query approaches
            try:
                # Primary query by thread_id
                project_name = os.environ.get("LANGCHAIN_PROJECT", "stella")
                print(f"   Using project name: '{project_name}'")
                
                # Try querying by thread_id first (might not work with all LangSmith versions)
                try:
                    all_runs = list(client.list_runs(
                        project_name=project_name,
                        thread_id=thread_id,
                    ))
                    print(f"   ‚úÖ Direct thread_id query completed. Found {len(all_runs)} runs")
                except Exception as thread_query_error:
                    print(f"   ‚ö†Ô∏è  Direct thread_id query failed: {thread_query_error}")
                    print(f"   üîÑ Falling back to manual filtering...")
                    
                    # Fallback: get all runs and filter manually
                    all_project_runs = list(client.list_runs(
                        project_name=project_name,
                        limit=100  # Get more runs for better chance of finding the thread
                    ))
                    
                    print(f"   üìä Retrieved {len(all_project_runs)} total runs from project")
                    
                    # Filter by thread_id manually
                    all_runs = []
                    for run in all_project_runs:
                        run_thread_id = None
                        
                        # Try multiple ways to get thread_id
                        if hasattr(run, 'thread_id') and run.thread_id:
                            run_thread_id = run.thread_id
                        elif hasattr(run, 'extra') and run.extra and 'thread_id' in run.extra:
                            run_thread_id = run.extra['thread_id']
                        elif hasattr(run, 'session_id') and run.session_id:
                            run_thread_id = run.session_id
                        
                        if run_thread_id == thread_id:
                            all_runs.append(run)
                    
                    print(f"   üéØ Manual filtering found {len(all_runs)} runs matching thread_id '{thread_id}'")
                
            except Exception as primary_query_error:
                print(f"   ‚ùå Primary query failed: {primary_query_error}")
                print(f"   üîÑ Trying alternative query without thread_id filter...")
                
                # Fallback: query recent runs and filter manually
                try:
                    recent_runs = list(client.list_runs(
                        project_name=project_name,
                        limit=50  # Get recent runs
                    ))
                    all_runs = [run for run in recent_runs if run.thread_id == thread_id]
                    print(f"   ‚úÖ Fallback query completed. Found {len(all_runs)} matching runs out of {len(recent_runs)} recent runs")
                    
                except Exception as fallback_error:
                    print(f"   ‚ùå Fallback query also failed: {fallback_error}")
                    raise fallback_error
            
        except Exception as query_error:
            print(f"   ‚ùå QUERY ERROR: {type(query_error).__name__}: {query_error}")
            import traceback
            print(f"   üìã Full traceback:")
            for line in traceback.format_exc().split('\n'):
                if line.strip():
                    print(f"      {line}")
            raise query_error
        finally:
            pass  # No signal cleanup needed

        # STEP 4: Analyze query results
        print(f"\nüìä STEP 4: Analyzing Query Results")
        if not all_runs:
            print(f"   ‚ùå No runs found for thread_id: {thread_id}")
            print(f"   üîç Possible causes:")
            print(f"      1. The session hasn't been traced to LangSmith")
            print(f"      2. The project name doesn't match (current: {os.environ.get('LANGCHAIN_PROJECT', 'stella')})")
            print(f"      3. The API key doesn't have access to this project")
            print(f"      4. The thread_id is incorrect or doesn't exist")
            print(f"      5. Tracing is disabled (LANGCHAIN_TRACING_V2 != 'true')")
            
            # Try to list available sessions for debugging
            try:
                print(f"   üîç Attempting to list recent sessions for debugging...")
                recent_runs = list(client.list_runs(
                    project_name=project_name,
                    limit=20
                ))
                if recent_runs:
                    unique_threads = set(run.thread_id for run in recent_runs if run.thread_id)
                    print(f"   üìã Found {len(unique_threads)} recent thread IDs:")
                    for i, tid in enumerate(list(unique_threads)[:10]):
                        print(f"      {i+1:2d}. {tid}")
                    
                    # Check if the requested thread_id is similar to any existing ones
                    print(f"   üîç Looking for similar thread IDs to: {thread_id}")
                    for tid in unique_threads:
                        if thread_id in tid or tid in thread_id:
                            print(f"      ‚ö†Ô∏è  Similar ID found: {tid}")
                        # Check if it's a UUID vs session format mismatch
                        if len(thread_id) == 36 and '-' in thread_id and tid.startswith('session_'):
                            print(f"      üí° UUID format requested but session format found: {tid}")
                        elif thread_id.startswith('session_') and len(tid) == 36 and '-' in tid:
                            print(f"      üí° Session format requested but UUID format found: {tid}")
                else:
                    print(f"   ‚ùå No recent runs found in project")
            except Exception as debug_error:
                print(f"   ‚ö†Ô∏è  Could not list recent sessions: {debug_error}")
            
            return None

        print(f"   ‚úÖ Found {len(all_runs)} runs total")
        print(f"   üìã Run details:")
        for i, run in enumerate(all_runs[:10]):  # Show first 10 runs
            status = "‚úÖ completed" if run.end_time else "üîÑ running"
            print(f"      {i+1:2d}. ID: {str(run.id)[:8]}... | Parent: {str(run.parent_run_id)[:8] + '...' if run.parent_run_id else 'None':12} | Name: {run.name:20} | Status: {status}")
        
        if len(all_runs) > 10:
            print(f"      ... and {len(all_runs) - 10} more runs")
        
        # STEP 5: Find main thread run
        print(f"\nüéØ STEP 5: Finding Main Thread Run")
        thread_run = next((r for r in all_runs if not r.parent_run_id), None)
        if not thread_run:
            print(f"   ‚ùå No main thread run found (all runs have parent_run_id)")
            print(f"   üîç This is unexpected - there should be a root run without parent")
            print(f"   üìã All run parent relationships:")
            for i, run in enumerate(all_runs):
                print(f"      {i+1}. {run.name} -> parent: {run.parent_run_id}")
            return None

        print(f"   ‚úÖ Found main thread run: {thread_run.id}")
        print(f"      Name: {thread_run.name}")
        print(f"      Start: {thread_run.start_time}")
        print(f"      End: {thread_run.end_time}")

        # STEP 6: Find child runs (workflow steps)
        print(f"\nüîó STEP 6: Finding Child Runs (Workflow Steps)")
        trace_nodes_runs = sorted(
            [r for r in all_runs if r.parent_run_id == thread_run.id],
            key=lambda r: r.start_time or r.end_time or 0
        )

        print(f"   ‚úÖ Found {len(trace_nodes_runs)} child runs")
        if trace_nodes_runs:
            print(f"   üìã Workflow steps:")
            for i, run in enumerate(trace_nodes_runs):
                status = "‚úÖ completed" if run.end_time else "üîÑ running"
                duration = ""
                if run.start_time and run.end_time:
                    duration = f" ({(run.end_time - run.start_time).total_seconds():.2f}s)"
                print(f"      {i+1:2d}. {run.name:20} | {status}{duration}")
        else:
            print(f"   ‚ùå No child runs found - this means no workflow steps were traced")
            return None

        # STEP 7: Extract tool calls from execute_tool runs
        print(f"\nüõ†Ô∏è  STEP 7: Extracting Tool Calls")
        tool_calls = []
        execute_tool_runs = [run for run in trace_nodes_runs if run.name == "execute_tool"]
        
        print(f"   Found {len(execute_tool_runs)} execute_tool runs")
        
        for i, run in enumerate(execute_tool_runs):
            print(f"   üîç Analyzing execute_tool run {i+1}/{len(execute_tool_runs)}")
            print(f"      Run ID: {run.id}")
            print(f"      Has inputs: {bool(run.inputs)}")
            print(f"      Has outputs: {bool(run.outputs)}")
            
            if run.inputs:
                print(f"      Input keys: {list(run.inputs.keys()) if isinstance(run.inputs, dict) else 'not a dict'}")
                
                if 'messages' in run.inputs:
                    messages = run.inputs['messages']
                    print(f"      Found {len(messages)} messages in inputs")
                    
                    # Look for AI messages with tool calls
                    for j, msg_dict in enumerate(reversed(messages)):
                        if isinstance(msg_dict, dict):
                            msg_type = msg_dict.get('type', 'unknown')
                            has_tool_calls = bool(msg_dict.get('tool_calls'))
                            print(f"         Message {j+1}: type={msg_type}, has_tool_calls={has_tool_calls}")
                            
                            if msg_type == 'ai' and has_tool_calls:
                                tool_calls_list = msg_dict['tool_calls']
                                print(f"         ‚úÖ Found {len(tool_calls_list)} tool calls")
                                
                                for k, tc in enumerate(tool_calls_list):
                                    tool_name = tc.get('name', 'unknown')
                                    tool_args = tc.get('args', {})
                                    print(f"            Tool {k+1}: {tool_name} with args: {tool_args}")
                                    
                                    # Create tool call object
                                    tool_call = {
                                        'name': tool_name,
                                        'arguments': tool_args,
                                        'status': 'completed' if run.end_time else 'executing',
                                        'execution_time': (run.end_time - run.start_time).total_seconds() * 1000 if run.end_time and run.start_time else 0,
                                        'timestamp': run.start_time.isoformat() if run.start_time else None,
                                        'run_id': str(run.id),
                                        'error': getattr(run, 'error', None)
                                    }
                                    
                                    # Add results if available
                                    if run.outputs:
                                        tool_call['result'] = run.outputs
                                        print(f"            Added outputs to tool call")
                                    
                                    tool_calls.append(tool_call)
                                    print(f"            ‚úÖ Tool call added to results")
                                
                                break  # Found the AI message with tool calls
                else:
                    print(f"      ‚ùå No 'messages' key in inputs")
            else:
                print(f"      ‚ùå No inputs found for this run")

        print(f"   ‚úÖ Extracted {len(tool_calls)} tool calls total")

        # STEP 8: Get graph structure
        print(f"\nüìä STEP 8: Getting Graph Structure")
        try:
            graph_json = app.get_graph().to_json()
            nodes_count = len(graph_json.get('nodes', []))
            edges_count = len(graph_json.get('edges', []))
            print(f"   ‚úÖ Graph structure retrieved: {nodes_count} nodes, {edges_count} edges")
        except Exception as graph_error:
            print(f"   ‚ö†Ô∏è  Could not get graph structure: {graph_error}")
            graph_json = {'nodes': [], 'edges': []}

        # STEP 9: Build final trace data
        print(f"\nüèóÔ∏è  STEP 9: Building Final Trace Data")
        trace_data = {
            'thread_id': thread_id,
            'tool_calls': tool_calls,
            'execution_path': [run.name for run in trace_nodes_runs],
            'graph_structure': {
                'nodes': graph_json.get('nodes', []),
                'edges': graph_json.get('edges', [])
            },
            'total_execution_time': sum(tc.get('execution_time', 0) for tc in tool_calls),
            'status': 'completed' if all(tc.get('status') == 'completed' for tc in tool_calls) else 'partial'
        }

        print(f"   ‚úÖ Trace data built successfully")
        print(f"      Thread ID: {trace_data['thread_id']}")
        print(f"      Tool calls: {len(trace_data['tool_calls'])}")
        print(f"      Execution path: {trace_data['execution_path']}")
        print(f"      Total execution time: {trace_data['total_execution_time']:.2f}ms")
        print(f"      Status: {trace_data['status']}")

        print(f"\n{'='*80}")
        print(f"‚úÖ LANGSMITH TRACE DEBUG - Successfully completed!")
        print(f"{'='*80}\n")
        
        return trace_data

    except Exception as e:
        print(f"\n{'='*80}")
        print(f"‚ùå LANGSMITH TRACE DEBUG - ERROR OCCURRED!")
        print(f"{'='*80}")
        print(f"Error type: {type(e).__name__}")
        print(f"Error message: {str(e)}")
        print(f"\nüìã Full traceback:")
        import traceback
        for line in traceback.format_exc().split('\n'):
            if line.strip():
                print(f"   {line}")
        print(f"{'='*80}\n")
        return None

def generate_trace_animation_frames(thread_id: str):
    """
    DEPRECATED: Utiliser get_langsmith_trace_data() √† la place.
    Maintenu pour compatibilit√© avec l'API existante.
    """
    print(f"--- DEPRECATED: generate_trace_animation_frames appel√© pour {thread_id}")
    print("--- Utilisez get_langsmith_trace_data() √† la place")
    return []

# --- Bloc test main ---
if __name__ == '__main__':
    def run_conversation(session_id: str, user_input: str):
        print(f"\n--- User: {user_input} ---")
        config = {"configurable": {"thread_id": session_id}}
        inputs = {"messages": [HumanMessage(content=user_input)]}
        final_message = None
        for event in app.stream(inputs, config=config, stream_mode="values"):
            final_message = event["messages"][-1]
        if final_message:
            print(f"\n--- R√©ponse finale de l'assistant ---\n{final_message.content}")
            if hasattr(final_message, 'image_base64'):
                print("\n[L'image a √©t√© g√©n√©r√©e et ajout√©e au message final]")

    conversation_id = f"test_session_{uuid.uuid4()}"
    run_conversation(conversation_id, "Qui sont les cr√©ateurs du projet ?")
