# agent.py
from dotenv import load_dotenv
load_dotenv()

# Variables d'environnement
import os

# Variables et donn√©es
import json
from typing import TypedDict, List, Annotated, Any
import pandas as pd
from io import StringIO
import textwrap

# Graphiques
import plotly.express as px
import plotly.io as pio
import plotly.graph_objects as go
import graphviz

# Num√©ro de session unique
import uuid

# Import de scripts
from src.fetch_data import APILimitError 
from src.chart_theme import stella_theme 

# LangGraph et LangChain
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, ToolMessage, SystemMessage
from langgraph.graph import StateGraph, END
from langgraph.graph.message import AnyMessage, add_messages
from langgraph.checkpoint.memory import MemorySaver
from langsmith import Client


# --- Import des tools ---
from tools import (
    available_tools,
    _fetch_recent_news_logic,
    _search_ticker_logic,
    _fetch_data_logic, 
    _preprocess_data_logic, 
    _analyze_risks_logic, 
    _create_dynamic_chart_logic,
    _fetch_profile_logic,
    _fetch_price_history_logic,
    _compare_fundamental_metrics_logic,
    _compare_price_histories_logic
    # _query_research_document_logic imported lazily in execute_tool_node
)

# Environment variables and constants
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")
OPENROUTER_MODEL = "moonshotai/kimi-k2:free"
LANGSMITH_TRACING = True
LANGSMITH_ENDPOINT = "https://api.smith.langchain.com"
LANGSMITH_API_KEY = os.getenv("LANGSMITH_API_KEY")
LANGSMITH_PROJECT = "stella"

if not OPENROUTER_API_KEY:
    raise ValueError("OPENROUTER_API_KEY n'a pas √©t√© enregistr√©e comme variable d'environnement.")

# Initialize the LLM with streaming support
llm = ChatOpenAI(
    model=OPENROUTER_MODEL,
    api_key=OPENROUTER_API_KEY,
    base_url="https://openrouter.ai/api/v1",
    temperature=0,
    streaming=True,  # Enable streaming
    default_headers={
        "HTTP-Referer": "https://github.com/DataScientest-Studio/nov24_cds_opa",
        "X-Title": "Stella Financial Assistant"
    }
)

# Objet AgentState pour stocker et modifier l'√©tat de l'agent entre les n≈ìuds
class AgentState(TypedDict):
    input: str
    ticker: str
    tickers: List[str]
    company_name: str
    fetched_df_json: str
    processed_df_json: str
    analysis: str
    plotly_json: str  
    messages: Annotated[List[AnyMessage], add_messages]
    error: str

# --- Prompt syst√®me (d√©finition du r√¥le de l'agent) ---
system_prompt = """Ton nom est Stella. Tu es une assistante experte financi√®re. Ton but principal est d'aider les utilisateurs en analysant des actions. Tu as √©t√© cr√©√©e par une √©quipe de recherche dans le cadre du **Projet OPA**.

Lien du repo Github du projet :
https://github.com/DataScientest-Studio/nov24_cds_opa
  
**Structure des r√©ponses**
Tu r√©pondras toujours de mani√®re structur√©e et claire, en utilisant des balises strong, puces, etc en markdown pour organiser l'information.

**R√®gle d'Or : Le Contexte est Roi**
Tu DOIS toujours prendre en compte les messages pr√©c√©dents pour comprendre la demande actuelle. 
Si un utilisateur demande de modifier ou d'ajouter quelque chose, tu dois te baser sur l'analyse ou le graphique qui vient d'√™tre montr√©. 
Ne recommence jamais une analyse de z√©ro si ce n'est pas explicitement demand√©.

**Gestion des Demandes Hors Sujet (Tr√®s Important !)**
Ton domaine d'expertise est STRICTEMENT l'analyse financi√®re des actions.
Si un utilisateur te pose une question qui n'est pas li√©e √† l'analyse d'actions, √† la finance, aux entreprises ou √† tes propres capacit√©s (par exemple : "Montre moi le cours de l'or", "Analyse le bitcoin", "raconte-moi une blague", "quelle est la capitale de la France ?", "donne-moi une recette de cuisine"), tu ne DOIS PAS utiliser d'outils.
Dans ce cas, tu dois r√©pondre directement et poliment que ce n'est pas dans ton domaine de comp√©tence, et rappeler ce que tu peux faire.

**Capacit√©s et Limites des Donn√©es (Information Cruciale)**
Tu dois imp√©rativement comprendre et respecter ces deux r√®gles :
1.  **Analyse Fondamentale (m√©triques comme ROE, dette, revenus) :** Cette analyse est **UNIQUEMENT DISPONIBLE POUR LES ACTIONS AM√âRICAINES** (cot√©es sur le NYSE, NASDAQ, etc.). Si on te demande une analyse fondamentale sur une action europ√©enne ou asiatique (ex: LVMH, Samsung, Cr√©dit Agricole), tu dois poliment d√©cliner en expliquant que cette fonctionnalit√© est limit√©e aux actions am√©ricaines, mais que tu peux tout de m√™me afficher son cours de bourse.
2.  **Analyse du Cours de Bourse (prix de l'action) :** Cette analyse est **DISPONIBLE POUR LES MARCH√âS MONDIAUX** (Europe, Asie, Am√©riques). Tu peux afficher et comparer les graphiques de prix pour n'importe quelle action, √† condition d'avoir le bon ticker (ex: `AIR.PA` pour Airbus, `005930.KS` pour Samsung).

**Liste des outils disponibles**
1.  `search_ticker`: Recherche le ticker boursier d'une entreprise √† partir de son nom. A utiliser uniquement si tu n'es pas totalement s√ªre du ticker √† choisir.
2.  `fetch_data`: R√©cup√®re les donn√©es financi√®res fondamentales pour un ticker. **RAPPEL : Ne fonctionne que pour les actions am√©ricaines.**
3.  `preprocess_data`: Pr√©pare et nettoie les donn√©es financi√®res. **RAPPEL : Ne fonctionne que sur les donn√©es am√©ricaines.**
4.  `analyze_risks`: Pr√©dit la performance d'une action. **RAPPEL : Ne fonctionne que sur les donn√©es am√©ricaines.**
5.  `display_price_chart`: Affiche un graphique de l'√©volution du prix (cours) d'une action. **Fonctionne pour les actions du monde entier.**
6.  `display_raw_data`: Affiche les donn√©es financi√®res brutes. **RAPPEL : Donn√©es am√©ricaines uniquement.**
7.  `display_processed_data`: Affiche les donn√©es financi√®res trait√©es. **RAPPEL : Donn√©es am√©ricaines uniquement.**
8.  `create_dynamic_chart`: Cr√©e un graphique interactif sur les donn√©es fondamentales. **RAPPEL : Donn√©es am√©ricaines uniquement.**
9.  `get_stock_news`: R√©cup√®re les derni√®res actualit√©s. **Fonctionne mieux pour les entreprises internationales.**
10. `get_company_profile`: R√©cup√®re le profil d'une entreprise. **Fonctionne pour les entreprises internationales.**
11. `compare_stocks`: Compare plusieurs entreprises sur une m√©trique financi√®re ou sur leur prix. **Lis attentivement les instructions ci-dessous pour cet outil.**
12. `query_research`: Recherche dans le rapport de projet via un syst√®me RAG pour trouver, expliquer ou r√©sumer des informations li√©es au contexte et √† la recherche du projet.

Si l'utilisateur te demande √† quoi tu sers, ce que tu sais faire, ou toute autre demande similaire, tu n'utiliseras **AUCUN OUTIL**.
Tu dois r√©pondre **EXACTEMENT** et **UNIQUEMENT** avec le texte suivant, sans rien ajouter ni modifier :

Je suis Stella üë©üèª, une assistante experte financi√®re cr√©√©e par une √©quipe de recherche dans le cadre du Projet OPA. Mon r√¥le principal est de t'aider √† analyser des actions.

### Ce que je peux faire pour toi :
*   üî¨ **Analyser une action en profondeur :** Je peux r√©aliser une analyse compl√®te d'une action am√©ricaine, de la collecte des donn√©es jusqu'√† une pr√©diction de risque.
*   üìä **Cr√©er des graphiques :** Je peux g√©n√©rer des graphiques dynamiques pour visualiser le prix d'une action ou d'autres m√©triques financi√®res.
*   ‚öñÔ∏è **Comparer des actions :** Je peux mettre en perspective plusieurs entreprises sur la base de leurs prix ou de leurs donn√©es fondamentales.
*   ‚ÑπÔ∏è **Donner des informations cl√©s :** Je peux te fournir des d√©tails sur une entreprise (secteur, CEO, description, etc.).
*   üß† **R√©pondre √† tes questions sur le projet :** Gr√¢ce √† ma fonction de RAG (Recherche Augment√©e), je peux chercher des informations dans la documentation du projet qui m'a cr√©√©e.

### Mes limites √† conna√Ætre
*   üá∫üá∏ Mon analyse fondamentale est limit√©e aux **actions am√©ricaines**.
*   üìà Les donn√©es de cours sont disponibles sur une p√©riode d' **un an maximum**.
*   ‚ö†Ô∏è Je ne fournis **aucun conseil d'investissement**. Mon but est de pr√©senter des donn√©es et des analyses objectives.

### Exemples de questions que tu peux me poser :
*   `Analyse l'action GOOGL`
*   `Montre-moi l'√©volution du ROE de Microsoft`
*   `Compare le cours de l'action de Apple et Nvidia sur 1 an`
*   `Parle-moi de l'entreprise Tesla`
*   `Quelle est la stack technique du projet Stella ?` (Ceci utilisera le RAG)

**Alors, pr√™t √† commencer ? Lance-toi !** üòä
---

**S√©quence d'analyse compl√®te (Actions Am√©ricaines Uniquement)**
Quand un utilisateur te demande une analyse compl√®te, tu DOIS appeler TOUS les outils n√©cessaires EN UNE SEULE FOIS :
1.  `search_ticker` si le nom de l'entreprise est donn√© plut√¥t que le ticker, et que tu n'es pas s√ªre du ticker.
2.  `fetch_data` avec le ticker demand√©.
3.  `preprocess_data` pour nettoyer les donn√©es.
4.  `analyze_risks` pour obtenir un verdict.

**IMPORTANT : Pour une analyse compl√®te, tu dois faire PLUSIEURS appels d'outils dans la m√™me r√©ponse.** Par exemple, si l'utilisateur demande "Analyse AAPL", tu dois appeler fetch_data, preprocess_data ET analyze_risks dans la m√™me r√©ponse, sans attendre de retour entre chaque outil.

Ta t√¢che est consid√©r√©e comme termin√©e apr√®s l'appel √† `analyze_risks`. La r√©ponse finale avec le graphique sera g√©n√©r√©e automatiquement.
Exemples de demandes devant d√©clencher une analyse compl√®te : 
* "Analyse Tesla"
* "Tu peux m'analyser Apple"
* "Quels risques d'investissement pour McDonald's ?"

**IDENTIFICATION DU TICKER** 
Si l'utilisateur donne un nom de soci√©t√© (comme 'Apple' ou 'Microsoft') au lieu d'un ticker (comme 'AAPL' ou 'MSFT'), et que tu es S√õR de conna√Ætre le ticker, tu peux l'utiliser directement.
Sinon, ton action doit √™tre d'utiliser l'outil `search_ticker` pour trouver le ticker correct.

**Analyse et Visualisation Dynamique (Actions Am√©ricaines Uniquement) :**
Quand un utilisateur te demande de "montrer", "visualiser" des m√©triques sp√©cifiques (par exemple, "montre-moi l'√©volution du ROE"), tu DOIS appeler TOUS les outils n√©cessaires EN UNE SEULE FOIS :
1.  Appelle `fetch_data`.
2.  Appelle `preprocess_data`.
3.  Appelle `create_dynamic_chart`.

**IMPORTANT : Tu dois faire ces TROIS appels d'outils dans la m√™me r√©ponse**, sans attendre de retour entre chaque outil.

**Analyse Comparative :**
Quand l'utilisateur demande de comparer plusieurs entreprises (ex: "compare le ROE de Google et Apple" ou "performance de l'action de MSFT vs GOOGL"), tu DOIS :
1.  **Identifier le type de comparaison :**
    *   Si la m√©trique est 'price' (prix, cours, performance de l'action), c'est une **comparaison de PRIX**. Elle fonctionne pour TOUTES les actions.
    *   Si la m√©trique est fondamentale (ROE, dette, marketCap, etc.), c'est une **comparaison FONDAMENTALE**. Elle ne fonctionne que pour les actions AM√âRICAINES. Si l'une des actions n'est pas am√©ricaine, tu dois refuser la comparaison et expliquer pourquoi, en proposant de comparer leur prix √† la place.
2.  Si les tickers ne sont pas donn√©s, utilise `search_ticker` pour chaque nom d'entreprise.
3.  Utilise l'outil `compare_stocks` en cons√©quence :
    *   Pour une comparaison **fondamentale** (am√©ricaine uniquement) : `comparison_type='fundamental'`, `metric='roe'` (par exemple).
    *   Pour une comparaison de **prix** (mondiale) : `comparison_type='price'`, `metric='price'`.

**AFFICHAGE DE DONNEES** 
Si l'utilisateur te demande d'afficher des donn√©es, tu dois appeler TOUS les outils n√©cessaires EN UNE SEULE FOIS :
* V√©rifier si l'entreprise est am√©ricaine ou internationale. R√©pondre en rappelant tes limites si l'entreprise n'est pas am√©ricaine. 
* Si des donn√©es ne sont pas disponibles dans le contexte, tu dois appeler `fetch_data` ET ENSUITE `display_raw_data` ou `display_processed_data` dans la m√™me r√©ponse.
* Si des donn√©es sont d√©j√† disponibles, appelle directement l'outil d'affichage appropri√©.

**IMPORTANT : Pour afficher des donn√©es trait√©es, tu dois faire fetch_data, preprocess_data ET display_processed_data dans la m√™me r√©ponse** si les donn√©es ne sont pas d√©j√† disponibles.

Tu dois bien comprendre que tu ne dois jamais afficher les donn√©es brutes ou trait√©es sans utiliser ces outils, car ils formatent correctement les donn√©es pour l'affichage.
Exemples : 
* "Affiche les donn√©es brutes de Tesla" -> `fetch_data` + `display_raw_data` (en une fois)
* "Affiche les donn√©es trait√©es d'Apple" -> `fetch_data` + `preprocess_data` + `display_processed_data` (en une fois)
* "Montre-moi les donn√©es" -> `display_raw_data` (si donn√©es d√©j√† disponibles)
* "Tableau des donn√©es" -> `display_raw_data` (si donn√©es d√©j√† disponibles)

**DEMANDES LIEES AU PROJET OPA**
Tu as acc√®s au document de recherche interne l'√©quipe qui t'a cr√©√©e via l'outil `query_research`.
Ton but est d'essayer de r√©pondre au maximum √† des questions qui pourraient √™tre en lien avec le projet OPA, ou avec ta cr√©ation.
Lorsqu'une question est pos√©e sur le projet (cr√©ateurs, fonctionnement, m√©thodologie, conclusion, ta stack technique, etc), tu DOIS TOUJOURS utiliser l'outil `query_research` pour obtenir des informations pertinentes.
Le contexte seul ne suffit pas, car il n'est pas toujours √† jour ou complet. APPELLE TOUJOURS CET OUTIL AVANT DE REPONDRE A UNE QUESTION CONCERNANT LE PROJET.
Utilise cet outil quand l'utilisateur:
* De mani√®re g√©n√©ral, pose n'importe quelle question concernant le contexte du projet.
* Demande comment tu as √©t√© cr√©√©e.
* Pose des questions sur les m√©thodologies, analyses ou conclusions de recherche de l'√©quipe, ou toute autre information concernant le projet dans lequel tu as √©t√© cr√©√©e.

**Gestion des Questions de Suivi (Tr√®s Important !)**

*   **Si je montre un graphique et que l'utilisateur dit "et pour [nouveau ticker] ?"**: Tu dois comprendre qu'il faut ajouter ce ticker au graphique existant. Tu rappelleras `compare_stocks` avec la liste des tickers initiaux PLUS le nouveau.
    *Ex: L'agent montre un graphique de prix pour `['AAPL', 'GOOG']`. L'utilisateur dit "rajoute Meta". L'agent doit appeler `compare_stocks(tickers=['AAPL', 'GOOG', 'META'], metric='price', ...)`.*

*   **Si l'utilisateur demande de changer la p√©riode**: Tu dois refaire le dernier graphique avec la nouvelle p√©riode.
    *Ex: L'agent montre un graphique sur 1 an. L'utilisateur dit "montre sur 5 ans". L'agent doit rappeler le m√™me outil avec `period_days=1260`.*

*   **Pour le NASDAQ 100**: Utilise le ticker de l'ETF `QQQ`. Pour le S&P 500, utilise `SPY`. Si l'utilisateur mentionne un indice, ajoute son ticker √† la liste pour la comparaison de prix.

Lorsuqe tu √©cris un ticker, entoure le toujours de backticks (``) pour le mettre en valeur. (ex: `AAPL`).
Tu dois toujours r√©pondre en fran√ßais et tutoyer ton interlocuteur.
Fais TOUJOURS r√©f√©rence √† **Stella comme toi m√™me**.
Fais attention au formatage de tes r√©ponses, √† toujours bien placer les balises markdown, et √† toujours les fermer.
"""

# --- D√©finition des noeuds du Graph ---

# Noeud 1 : agent_node, point d'entr√©e et appel du LLM 
def agent_node(state: AgentState):
    """Le 'cerveau' de l'agent. D√©cide du prochain outil √† appeler."""
    print("\n--- AGENT: D√©cision de la prochaine √©tape... ---")

    # On commence par le prompt syst√®me pour donner le r√¥le
    current_messages = [SystemMessage(content=system_prompt)]
    
    # --- INJECTION DE CONTEXTE DYNAMIQUE ---
    data_to_inspect_json = state.get("processed_df_json") or state.get("fetched_df_json")
    
    if data_to_inspect_json:
        try:
            df = pd.read_json(StringIO(data_to_inspect_json), orient='split')
            available_columns = df.columns.tolist()
            
            # On cr√©e un message syst√®me temporaire avec les colonnes disponibles
            context_message = SystemMessage(
                content=(
                    f"\n\n--- CONTEXTE ACTUEL DES DONN√âES ---\n"
                    f"Des donn√©es sont disponibles.\n"
                    f"Si tu utilises `create_dynamic_chart`, tu DOIS choisir les colonnes EXACTEMENT dans cette liste :\n"
                    f"{available_columns}\n"
                    f"---------------------------------\n"
                )
            )
            # On ajoute le contexte √† notre liste de messages
            current_messages.append(context_message)

        except Exception as e:
            print(f"Avertissement: Impossible d'injecter le contexte des colonnes. Erreur: {e}")

    # On ajoute l'historique de la conversation depuis l'√©tat
    current_messages.extend(state['messages'])

    # üïê TIMING: Start measuring LLM inference time
    import time
    llm_start_time = time.time()
    print(f"‚è±Ô∏è  [LLM] Starting inference call to {OPENROUTER_MODEL}...")
    
    # On invoque le LLM avec la liste de messages compl√®te
    # Cette liste est locale et ne modifie pas l'√©tat directement
    response = llm.bind_tools(available_tools).invoke(current_messages)
    
    # üïê TIMING: End measuring LLM inference time
    llm_end_time = time.time()
    llm_duration = llm_end_time - llm_start_time
    print(f"‚è±Ô∏è  [LLM] Inference completed in {llm_duration:.2f} seconds")
    
    print(f"response.content: {response.content}")
    return {"messages": [response]}

# Noeud 2 : execute_tool_node, ex√©cute les outils en se basant sur la d√©cision de l'agent_node (Noeud 1).
def execute_tool_node(state: AgentState):
    """Le "pont" qui ex√©cute la logique r√©elle et met √† jour l'√©tat."""
    print("\n--- OUTILS: Ex√©cution d'un outil ---")
    action_message = next((msg for msg in reversed(state['messages']) if isinstance(msg, AIMessage) and msg.tool_calls), None)
    if not action_message:
        raise ValueError("Aucun appel d'outil trouv√© dans le dernier AIMessage.")

    tool_outputs = []
    current_state_updates = {}
    
    # Create a working copy of state that gets updated as we execute tools
    working_state = state.copy()
    
    # On g√®re le cas o√π plusieurs outils sont appel√©s, bien que ce soit rare ici.
    for tool_call in action_message.tool_calls:
        tool_name = tool_call['name']
        tool_args = tool_call['args']
        tool_id = tool_call['id']
        print(f"Le LLM a d√©cid√© d'appeler le tool : {tool_name} - avec les arguments : {tool_args}")
        
        # üïê TIMING: Start measuring tool execution time
        import time
        tool_start_time = time.time()
        print(f"‚è±Ô∏è  [TOOL] Starting execution of '{tool_name}'...")

        try:
            if tool_name == "search_ticker":
                company_name = tool_args.get("company_name")
                ticker = _search_ticker_logic(company_name=company_name)
                # On stocke le ticker ET le nom de l'entreprise
                current_state_updates["ticker"] = ticker
                current_state_updates["company_name"] = company_name 
                tool_outputs.append(ToolMessage(tool_call_id=tool_id, content=f"[Ticker `{ticker}` trouv√©.]"))

            elif tool_name == "fetch_data":
                try:
                    output_df = _fetch_data_logic(ticker=tool_args.get("ticker"))
                    current_state_updates["fetched_df_json"] = output_df.to_json(orient='split')
                    current_state_updates["ticker"] = tool_args.get("ticker")
                    # Update working state immediately for next tool
                    working_state["fetched_df_json"] = current_state_updates["fetched_df_json"]
                    working_state["ticker"] = current_state_updates["ticker"]
                    tool_outputs.append(ToolMessage(tool_call_id=tool_id, content="[Donn√©es r√©cup√©r√©es avec succ√®s.]"))
                except APILimitError as e:
                    user_friendly_error = "D√©sol√©, il semble que j'aie un probl√®me d'acc√®s √† mon fournisseur de donn√©es. Peux-tu r√©essayer plus tard ?"
                    tool_outputs.append(ToolMessage(tool_call_id=tool_id, content=json.dumps({"error": user_friendly_error})))
                    current_state_updates["error"] = user_friendly_error
            
            elif tool_name == "get_stock_news":
                
                # 1. On cherche le ticker dans les arguments fournis par le LLM, SINON dans l'√©tat.
                ticker = tool_args.get("ticker") or state.get("ticker")
                
                # 2. Si apr√®s tout √ßa, on n'a toujours pas de ticker, c'est une vraie erreur.
                if not ticker:
                    raise ValueError("Impossible de d√©terminer un ticker pour chercher les nouvelles, ni dans la commande, ni dans le contexte.")
                
                # 3. On fait pareil pour le nom de l'entreprise (qui est optionnel mais utile)
                # On utilise le ticker comme nom si on n'a rien d'autre.
                company_name = tool_args.get("company_name") or state.get("company_name") or ticker
                
                # 4. On appelle la logique avec les bonnes informations.
                news_summary = _fetch_recent_news_logic(
                    ticker=ticker, 
                    company_name=company_name
                )

                tool_outputs.append(ToolMessage(tool_call_id=tool_id, content=news_summary))
                
            elif tool_name == "preprocess_data":
                # Check working state first, then fall back to original state
                fetched_df_json = current_state_updates.get("fetched_df_json") or working_state.get("fetched_df_json")
                if not fetched_df_json:
                    raise ValueError("Impossible de pr√©traiter les donn√©es car elles n'ont pas encore √©t√© r√©cup√©r√©es.")
                fetched_df = pd.read_json(StringIO(fetched_df_json), orient='split')
                output = _preprocess_data_logic(df=fetched_df)
                current_state_updates["processed_df_json"] = output.to_json(orient='split')
                # Update working state immediately for next tool
                working_state["processed_df_json"] = current_state_updates["processed_df_json"]
                tool_outputs.append(ToolMessage(tool_call_id=tool_id, content="[Donn√©es pr√©trait√©es avec succ√®s.]"))

            elif tool_name == "analyze_risks":
                # Check working state first, then fall back to original state  
                processed_df_json = current_state_updates.get("processed_df_json") or working_state.get("processed_df_json")
                if not processed_df_json:
                    raise ValueError("Impossible de faire une pr√©diction car les donn√©es n'ont pas encore √©t√© pr√©trait√©es.")
                processed_df = pd.read_json(StringIO(processed_df_json), orient='split')
                output = _analyze_risks_logic(processed_data=processed_df)
                current_state_updates["analysis"] = output
                # Update working state immediately for potential next tool
                working_state["analysis"] = current_state_updates["analysis"]
                tool_outputs.append(ToolMessage(tool_call_id=tool_id, content=output))
            
            elif tool_name == "create_dynamic_chart":
                # Check working state first for data access in tool chains
                data_json_for_chart = (
                    current_state_updates.get("processed_df_json") or 
                    working_state.get("processed_df_json") or 
                    current_state_updates.get("fetched_df_json") or 
                    working_state.get("fetched_df_json")
                )
                if not data_json_for_chart:
                    raise ValueError("Aucune donn√©e disponible pour cr√©er un graphique.")
                
                # On convertit le JSON en DataFrame
                df_for_chart = pd.read_json(StringIO(data_json_for_chart), orient='split')
                
                chart_json = _create_dynamic_chart_logic(
                    data=df_for_chart,  # <--- Le DataFrame est pass√© directement
                    chart_type=tool_args.get('chart_type'),
                    x_column=tool_args.get('x_column'),
                    y_column=tool_args.get('y_column'),
                    title=tool_args.get('title'),
                    color_column=tool_args.get('color_column')
                )
                
                
                if "Erreur" in chart_json:
                    raise ValueError(chart_json) # Transforme l'erreur de l'outil en exception
                
                current_state_updates["plotly_json"] = chart_json
                tool_outputs.append(ToolMessage(tool_call_id=tool_id, content="[Graphique interactif cr√©√©.]"))

            elif tool_name in ["display_raw_data", "display_processed_data"]:
                # V√©rifie la disponibilit√© des donn√©es en tenant compte de la cha√Æne d'outils en cours
                if tool_name == "display_raw_data":
                    df_json = (
                        current_state_updates.get("fetched_df_json") or
                        working_state.get("fetched_df_json") or
                        state.get("fetched_df_json")
                    )
                else:  # display_processed_data
                    df_json = (
                        current_state_updates.get("processed_df_json") or
                        working_state.get("processed_df_json") or
                        state.get("processed_df_json")
                    )

                if not df_json:
                    raise ValueError("Aucune donn√©e disponible √† afficher.")

                # Rien √† renvoyer ici, on laisse le noeud prepare_data_display attacher le bon DataFrame
                tool_outputs.append(ToolMessage(tool_call_id=tool_id, content="[Pr√©paration de l'affichage des donn√©es.]"))

            elif tool_name == "get_company_profile":
                ticker = tool_args.get("ticker")
                profile_json = _fetch_profile_logic(ticker=ticker)
                tool_outputs.append(ToolMessage(tool_call_id=tool_id, content=profile_json))
            
            elif tool_name == "display_price_chart":
                ticker = tool_args.get("ticker")
                period = tool_args.get("period_days", 252) # Utilise la valeur par d√©faut si non fournie
                
                # On appelle notre logique pour r√©cup√©rer les donn√©es de prix
                price_df = _fetch_price_history_logic(ticker=ticker, period_days=period)
                
                # On cr√©e le graphique directement ici
                fig = px.line(
                    price_df, 
                    x=price_df.index, 
                    y='close', 
                    title=f"Historique du cours de {ticker.upper()} sur {period} jours",
                    color_discrete_sequence=stella_theme['colors']

                )
                fig.update_layout(template=stella_theme['template'], font=stella_theme['font'], xaxis_title="Date", yaxis_title="Prix de cl√¥ture (USD)")
                
                # On convertit en JSON et on met √† jour l'√©tat
                chart_json = pio.to_json(fig)
                current_state_updates["plotly_json"] = chart_json
                tool_outputs.append(ToolMessage(tool_call_id=tool_id, content="[Graphique de prix cr√©√© avec succ√®s.]"))

            elif tool_name == "compare_stocks":
                tickers = tool_args.get("tickers")
                metric = tool_args.get("metric")
                comparison_type = tool_args.get("comparison_type", "fundamental")

                if comparison_type == 'fundamental':
                    # On appelle la fonction qui retourne l'historique
                    comp_df = _compare_fundamental_metrics_logic(tickers=tickers, metric=metric)
                    fig = px.line(
                        comp_df,
                        x=comp_df.index,
                        y=comp_df.columns,
                        title=f"√âvolution de la m√©trique '{metric.upper()}'",
                        labels={'value': metric.upper(), 'variable': 'Ticker', 'calendarYear': 'Ann√©e'},
                        markers=True, # Les marqueurs sont utiles pour voir les points de donn√©es annuels
                        color_discrete_sequence=stella_theme['colors']  # Utilise la palette de couleurs Stella
                    )
                elif comparison_type == 'price':
                    # La logique pour le prix ne change pas, elle est d√©j√† une √©volution
                    period = tool_args.get("period_days", 252)
                    comp_df = _compare_price_histories_logic(tickers=tickers, period_days=period)
                    fig = px.line(
                        comp_df,
                        title=f"Comparaison de la performance des actions (Base 100)",
                        labels={'value': 'Performance Normalis√©e (Base 100)', 'variable': 'Ticker', 'index': 'Date'},
                        color_discrete_sequence=stella_theme['colors']
                    )
                else:
                    raise ValueError(f"Type de comparaison inconnu: {comparison_type}")

                # Le reste du code est commun et ne change pas
                fig.update_layout(template="plotly_white")
                chart_json = pio.to_json(fig)
                current_state_updates["plotly_json"] = chart_json
                current_state_updates["tickers"] = tickers
                tool_outputs.append(ToolMessage(tool_call_id=tool_id, content="[Graphique de comparaison cr√©√©.]"))
            
            elif tool_name == "query_research":
                query = tool_args.get("query")
                # Lazy import to avoid initialization delays
                from src.pdf_research import query_research_document as _query_research_document_logic
                research_result = _query_research_document_logic(query=query)
                tool_outputs.append(ToolMessage(tool_call_id=tool_id, content=research_result))
            
        except Exception as e:
            # Bloc de capture g√©n√©rique pour toutes les autres erreurs
            error_msg = f"Erreur lors de l'ex√©cution de l'outil '{tool_name}': {repr(e)}"
            tool_outputs.append(ToolMessage(tool_call_id=tool_id, content=f"[ERREUR: {error_msg}]"))
            current_state_updates["error"] = error_msg
            print(error_msg)
        
        # üïê TIMING: End measuring tool execution time
        tool_end_time = time.time()
        tool_duration = tool_end_time - tool_start_time
        print(f"‚è±Ô∏è  [TOOL] '{tool_name}' completed in {tool_duration:.2f} seconds")
            
    current_state_updates["messages"] = tool_outputs
    return current_state_updates

# Noeud 3 : generate_final_response_node, synth√©tise la r√©ponse finale √† partir de l'√©tat.
def generate_final_response_node(state: AgentState):
    """
    G√©n√®re la r√©ponse textuelle finale ET le graphique Plotly par d√©faut apr√®s une analyse compl√®te.
    Ce noeud est le point de sortie pour une analyse de pr√©diction.
    """
    print("\n--- AGENT: G√©n√©ration de la r√©ponse finale et du graphique ---")
    
    # --- 1. R√©cup√©ration des informations de l'√©tat ---
    ticker = state.get("ticker", "l'action")
    analysis_result = state.get("analysis", "inconnu")
    processed_df_json = state.get("processed_df_json")

    # --- 2. Construction de la r√©ponse textuelle ---
    response_content = ""
    latest_year_str = "r√©centes"
    next_year_str = "prochaine"
    
    if processed_df_json:
        try:
            df = pd.read_json(StringIO(processed_df_json), orient='split')
            if not df.empty and 'calendarYear' in df.columns:
                latest_year_str = df['calendarYear'].iloc[-1]
                next_year_str = str(int(latest_year_str) + 1)
        except Exception as e:
            print(f"Avertissement : Impossible d'extraire l'ann√©e des donn√©es : {e}")

    # Logique de la r√©ponse textuelle bas√©e sur la pr√©diction
    if analysis_result == "Risque √âlev√© D√©tect√©":
        response_content = (
            f"‚ö†Ô∏è **Attention !** Pour l'action `{ticker.upper()}`, en se basant sur les donn√©es de `{latest_year_str}` (derni√®res donn√©es disponibles), mon analyse a d√©tect√© des signaux indiquant un **risque √©lev√© de sous-performance pour l'ann√©e √† venir (`{next_year_str}`)**.\n\n"
            "Mon mod√®le est particuli√®rement confiant dans cette √©valuation. Je te conseille la plus grande prudence."
        )
    elif analysis_result == "Aucun Risque Extr√™me D√©tect√©":
        response_content = (
            f"Pour l'action `{ticker.upper()}`, en se basant sur les donn√©es de `{latest_year_str}` (derni√®res donn√©es disponibles), mon analyse n'a **pas d√©tect√© de signaux de danger extr√™me pour l'ann√©e √† venir (`{next_year_str}`)**.\n\n"
            "**Important :** Cela ne signifie pas que c'est un bon investissement. Cela veut simplement dire que mon mod√®le, sp√©cialis√© dans la d√©tection de signaux tr√®s n√©gatifs, n'en a pas trouv√© ici. Mon r√¥le est de t'aider √† √©viter une erreur √©vidente, pas de te garantir un succ√®s."
        )
    else:
        response_content = f"L'analyse des donn√©es pour **{ticker.upper()}** a √©t√© effectu√©e, mais le r√©sultat de la pr√©diction n'a pas pu √™tre interpr√©t√©."

    # --- 3. Cr√©ation du graphique de synth√®se ---
    chart_json = None
    explanation_text = None 
    if processed_df_json:
        try:
            df = pd.read_json(StringIO(processed_df_json), orient='split')
            # Les colonnes dont nous avons besoin pour ce nouveau graphique
            metrics_to_plot = ['calendarYear', 'revenuePerShare_YoY_Growth', 'earningsYield']
            
            # On s'assure que les colonnes existent
            plot_cols = [col for col in metrics_to_plot if col in df.columns]
            
            if not df.empty and all(col in plot_cols for col in metrics_to_plot):
                chart_title = f"Analyse Croissance vs. Valorisation pour {ticker.upper()}"
                
                # Cr√©er la figure de base
                fig = go.Figure()

                # 1. Ajouter les barres de Croissance du CA (% YoY) sur l'axe Y1
                fig.add_trace(go.Scatter(
                    x=df['calendarYear'],
                    y=df['revenuePerShare_YoY_Growth'],
                    name='Croissance du CA (%)',
                    mode='lines+markers', # On sp√©cifie le mode ligne avec marqueurs
                    line=dict(color=stella_theme['colors'][1]), # On utilise 'line' pour la couleur
                    yaxis='y1'
                ))

                # 2. Ajouter la ligne de Valorisation (Earnings Yield) sur l'axe Y2
                fig.add_trace(go.Scatter(
                    x=df['calendarYear'],
                    y=df['earningsYield'],
                    name='Rendement des B√©n√©fices (Valorisation)',
                    mode='lines+markers',
                    line=dict(color=stella_theme['colors'][0]), # Bleu Stella
                    yaxis='y2'
                ))
                
                # Ajouter une ligne √† z√©ro pour mieux visualiser la croissance positive/n√©gative
                fig.add_hline(y=0, line_width=1, line_dash="dash", line_color="black", yref="y1")

                # 3. Configurer les axes et le layout
                fig.update_layout(
                    title_text=chart_title,
                    template=stella_theme['template'],
                    font=stella_theme['font'],
                    margin=dict(r=320),
                    xaxis=dict(
                        title='Ann√©e',
                        type='category' # Force l'axe √† traiter les ann√©es comme des √©tiquettes uniques
                    ),
                    yaxis=dict(
                        title=dict(
                            text='Croissance Annuelle du CA',
                            font=dict(color=stella_theme['colors'][1])
                        ),
                        tickfont=dict(color=stella_theme['colors'][1]),
                        ticksuffix=' %'
                    ),
                    yaxis2=dict(
                        title=dict(
                            text='Rendement b√©n√©ficiaire (inverse du P/E)',
                            font=dict(color=stella_theme['colors'][0]) 
                        ),
                        tickfont=dict(color=stella_theme['colors'][0]),
                        anchor='x',
                        overlaying='y',
                        side='right',
                        tickformat='.2%'
                    ),
                    legend=dict(
                        orientation="v",
                        yanchor="top",
                        y=1, # On aligne le haut de la l√©gende avec le haut du graphique
                        xanchor="left",
                        x=1.20, # On pousse la l√©gende un peu plus √† droite
                        bordercolor="rgba(0, 0, 0, 0.2)", # Bordure l√©g√®re
                        borderwidth=1,
                        title_text="L√©gende"
                    )
                )
                
                chart_json = pio.to_json(fig)
                response_content += f"\n\n**Voici une visualisation de sa croissance par rapport √† sa valorisation :**"
                
                # On cr√©e le texte explicatif et on l'ajoute √† la suite
                explanation_text = textwrap.dedent("""
                    ---
                    **Comment interpr√©ter ce graphique ?**

                    Ce graphique croise deux questions cl√©s : "L'entreprise grandit-elle ?" et "Quel prix le march√© paie-t-il pour cette croissance ?".

                    *   üü£ **La ligne violette (Croissance)** : Elle montre la tendance de la croissance du chiffre d'affaires. Une courbe ascendante indique une acc√©l√©ration.
                    *   üü¢ **La ligne verte (Valorisation)** : Elle repr√©sente le rendement des b√©n√©fices (l'inverse du fameux P/E Ratio). **Plus cette ligne est haute, plus l'action est consid√©r√©e comme "bon march√©"** par rapport √† ses profits. Une ligne basse indique une action "ch√®re".

                    **L'analyse cl√© :** Id√©alement, on recherche une croissance qui acc√©l√®re (ligne üü£ qui monte) avec une valorisation qui reste raisonnable (ligne üü¢ stable ou qui monte). Une croissance qui ralentit (ligne üü£ qui plonge) alors que l'action devient plus ch√®re (ligne üü¢ qui plonge) est souvent un signal de prudence.
                """)
            else:
                response_content += "\n\n(Impossible de g√©n√©rer le graphique de synth√®se Croissance/Valorisation : donn√©es ou colonnes manquantes)."

        except Exception as e:
            print(f"Erreur lors de la cr√©ation du graphique par d√©faut : {e}")
            response_content += "\n\n(Je n'ai pas pu g√©n√©rer le graphique associ√© en raison d'une erreur.)"
    
    # --- 4. Cr√©ation du message final ---
    final_message = AIMessage(content=response_content)
    if chart_json:
        # On attache le graphique ET le texte explicatif au message
        setattr(final_message, 'plotly_json', chart_json)
        if explanation_text:
            setattr(final_message, 'explanation_text', explanation_text)

    return {"messages": [final_message]}

# Noeud 4 : cleanup_state_node, nettoie l'√©tat pour √©viter de stocker des donn√©es lourdes.
def cleanup_state_node(state: AgentState):
    """
    Nettoie l'√©tat pour la prochaine interaction.
    Il efface les donn√©es sp√©cifiques √† la derni√®re r√©ponse (pr√©diction, graphique)
    mais GARDE le contexte principal (donn√©es brutes et trait√©es, ticker)
    pour permettre des questions de suivi.
    """
    print("\n--- SYSTEM: Nettoyage partiel de l'√©tat avant la sauvegarde ---")
    
    # On garde : 'ticker', 'tickers', 'company_name', 'fetched_df_json', 'processed_df_json'
    # On supprime (r√©initialise) :
    return {
        "analysis": "",   # Efface la pr√©diction pr√©c√©dente
        "plotly_json": "",  # Efface le graphique pr√©c√©dent
        "error": ""         # Efface toute erreur pr√©c√©dente
    }

# Noeuds suppl√©mentaires de pr√©paration pour l'affichage des donn√©es, graphiques, actualit√©s et profil d'entreprise.
def prepare_data_display_node(state: AgentState):
    """Pr√©pare un AIMessage avec un DataFrame sp√©cifique attach√©."""
    print("\n--- AGENT: Pr√©paration du DataFrame pour l'affichage ---")
    
    tool_name_called = next(msg for msg in reversed(state['messages']) if isinstance(msg, AIMessage) and msg.tool_calls).tool_calls[-1]['name']

    if tool_name_called == "display_processed_data" and state.get("processed_df_json"):
        df_json = state["processed_df_json"]
        message_content = "Voici les donn√©es **pr√©-trait√©es** que tu as demand√©es :"
    elif tool_name_called == "display_raw_data" and state.get("fetched_df_json"):
        df_json = state["fetched_df_json"]
        message_content = "Voici les donn√©es **brutes** que tu as demand√©es :"
    else:
        final_message = AIMessage(content="D√©sol√©, les donn√©es demand√©es ne sont pas disponibles.")
        return {"messages": [final_message]}

    final_message = AIMessage(content=message_content)
    setattr(final_message, 'dataframe_json', df_json)
    return {"messages": [final_message]}

def prepare_chart_display_node(state: AgentState):
    """Pr√©pare un AIMessage avec le graphique Plotly demand√© par l'utilisateur."""
    print("\n--- AGENT: Pr√©paration du graphique pour l'affichage ---")
    
    # Laisse le LLM g√©n√©rer une courte phrase d'introduction
    response = ("Voici le graphique demand√© : ")
    
    final_message = AIMessage(content=response)
    setattr(final_message, 'plotly_json', state["plotly_json"])
    
    return {"messages": [final_message]}

def prepare_news_display_node(state: AgentState):
    """Pr√©pare un AIMessage avec les actualit√©s format√©es pour l'affichage."""
    print("\n--- AGENT: Pr√©paration de l'affichage des actualit√©s ---")
    
    # 1. Retrouver le ToolMessage qui contient le r√©sultat des actualit√©s
    # On cherche le dernier message de type ToolMessage dans l'historique
    tool_message = next((msg for msg in reversed(state['messages']) if isinstance(msg, ToolMessage)), None)
    
    if not tool_message or not tool_message.content:
        final_message = AIMessage(content="D√©sol√©, je n'ai pas pu r√©cup√©rer les actualit√©s.")
        return {"messages": [final_message]}

    # 2. Pr√©parer le contenu textuel de la r√©ponse
    ticker = state.get("ticker", "l'entreprise")
    company_name = state.get("company_name", ticker)
    
    response_content = f"Voici les derni√®res actualit√©s que j'ai trouv√©es pour **{company_name.title()} ({ticker.upper()})** :"
    
    final_message = AIMessage(content=response_content)
    
    # 3. Attacher le JSON des actualit√©s au message final
    # Le front-end (Streamlit) utilisera cet attribut pour afficher les articles
    setattr(final_message, 'news_json', tool_message.content)
    
    return {"messages": [final_message]}

def prepare_profile_display_node(state: AgentState):
    """Pr√©pare un AIMessage avec le profil de l'entreprise pour l'affichage."""
    print("\n--- AGENT: Pr√©paration de l'affichage du profil d'entreprise ---")
    
    tool_message = next((msg for msg in reversed(state['messages']) if isinstance(msg, ToolMessage)), None)
    
    if not tool_message or not tool_message.content:
        final_message = AIMessage(content="D√©sol√©, je n'ai pas pu r√©cup√©rer le profil de l'entreprise.")
        return {"messages": [final_message]}

    prompt = f"""
    Voici les informations de profil pour une entreprise au format JSON :
    {tool_message.content}
    **INFORMATION CRUCIALE :**
    TU DOIS r√©diger une r√©ponse format√©e en markdown pour pr√©senter ces informations √† l'utilisateur.
    R√©dige une r√©ponse la plus exhaustive et agr√©able possible pour pr√©senter ces informations √† l'utilisateur.
    Mets en avant le nom de l'entreprise, son secteur et son CEO, mais n'omet aucune information qui n'est pas null dans le JSON.
    Tu n'afficheras pas l'image du logo, l'UI s'en chargera, et tu n'as pas besoin de la mentionner.
    Pr√©sente les informations de mani√®re sobre en listant les points du JSON.
    Si il y a un champ null, TU DOIS TOUJOURS le compl√©ter via tes connaissances, sans inventer de donn√©es.
    Si tu ne trouves pas d'informations, indique simplement "Inconnu" ou "Non disponible".
    Termine en donnant le lien vers leur site web.
    """
    response = llm.invoke(prompt)
    print(f"response.content: {response.content}")
    final_message = AIMessage(content=response.content)
    
    # On attache le JSON pour que le front-end puisse afficher l'image du logo !
    setattr(final_message, 'profile_json', tool_message.content)
    
    return {"messages": [final_message]}

# Noeud de gestion des erreurs
def handle_error_node(state: AgentState):
    """
    G√©n√®re un message d'erreur clair pour l'utilisateur, puis pr√©pare le nettoyage de l'√©tat.
    Ce noeud est appel√© par le routeur chaque fois que le champ 'error' est rempli.
    """
    print("\n--- AGENT: Gestion de l'erreur... ---")
    error_message = state.get("error", "Une erreur inconnue est survenue.")
    
    # On cr√©e une r√©ponse claire et format√©e pour l'utilisateur.
    user_facing_error = textwrap.dedent(f"""
        D√©sol√©, une erreur est survenue et je n'ai pas pu terminer ta demande.
        
        **D√©tail de l'erreur :**
        ```
        {error_message}
        ```
        
        Peux-tu essayer de reformuler ta question ou tenter une autre action ?
    """)
    
    # On met cette r√©ponse dans un AIMessage qui sera affich√© dans le chat.
    # L'√©tape suivante sera le nettoyage de l'√©tat.
    return {"messages": [AIMessage(content=user_facing_error)]}

# --- Router pour diriger le flux du graph ---
def router(state: AgentState) -> str:
    """Le routeur principal du graphe, version finale robuste avec support du tool chaining."""
    print("\n--- ROUTEUR: √âvaluation de l'√©tat pour choisir la prochaine √©tape ---")

    # On r√©cup√®re les messages de l'√©tat
    messages = state['messages']
    
    # Y a-t-il une erreur ? C'est la priorit√© absolue.
    if state.get("error"):
        print("Routeur -> D√©cision: Erreur d√©tect√©e, passage au gestionnaire d'erreurs.")
        return "handle_error"

    # Le dernier message est-il une d√©cision de l'IA d'appeler un outil ?
    last_message = messages[-1]

    if isinstance(last_message, AIMessage) and not last_message.tool_calls:
        print("Routeur -> D√©cision: L'IA a fourni une r√©ponse textuelle. Fin du cycle.")
        return END
    if isinstance(last_message, AIMessage) and last_message.tool_calls:
        # C'est la premi√®re fois qu'on voit cette d√©cision, on doit ex√©cuter l'outil.
        print("Routeur -> D√©cision: Appel d'outil demand√©, passage √† execute_tool.")
        return "execute_tool"

    # Si le dernier message n'est PAS un appel √† un outil, cela signifie probablement
    # qu'un outil vient de s'ex√©cuter. Nous devons d√©cider o√π aller ensuite.
    
    # On retrouve le dernier appel √† un outil fait par l'IA
    ai_message_with_tool_call = next(
        (msg for msg in reversed(messages) if isinstance(msg, AIMessage) and msg.tool_calls),
        None
    )
    # S'il n'y en a pas, on ne peut rien faire de plus.
    if not ai_message_with_tool_call:
        print("Routeur -> D√©cision: Aucune action claire √† prendre (pas d'appel d'outil trouv√©), fin du processus.")
        return END
    
    # Check if there are multiple tool calls to execute in sequence
    remaining_tool_calls = ai_message_with_tool_call.tool_calls
    executed_tool_calls = [msg for msg in reversed(messages) if isinstance(msg, ToolMessage)]
    
    print(f"--- ROUTEUR: Nombre total d'outils √† ex√©cuter: {len(remaining_tool_calls)}, d√©j√† ex√©cut√©s: {len(executed_tool_calls)}")
    
    # If we still have tools to execute from the same AI message, continue executing them
    if len(executed_tool_calls) < len(remaining_tool_calls):
        next_tool_name = remaining_tool_calls[len(executed_tool_calls)]['name']
        print(f"Routeur -> D√©cision: Outil suivant dans la cha√Æne: '{next_tool_name}', continuer l'ex√©cution.")
        return "execute_tool"
        
    # All tools from the current AI message have been executed, check the last executed tool
    tool_name = ai_message_with_tool_call.tool_calls[-1]['name']
    print(f"--- ROUTEUR: Tous les outils de la cha√Æne ont √©t√© ex√©cut√©s, le dernier √©tait '{tool_name}'. ---")

    # Maintenant, on d√©cide de la suite en fonction du dernier outil de la cha√Æne.
    if tool_name == 'analyze_risks':
        return "generate_final_response"
    elif tool_name == 'compare_stocks': 
        return "prepare_chart_display"
    elif tool_name == 'display_price_chart':
        return "prepare_chart_display"
    elif tool_name in ['display_raw_data', 'display_processed_data']:
        return "prepare_data_display"
    elif tool_name == 'create_dynamic_chart':
        return "prepare_chart_display"
    elif tool_name == 'get_stock_news':
        return "prepare_news_display"
    elif tool_name == 'get_company_profile': 
        return "prepare_profile_display"
    else: # Pour search_ticker, fetch_data, preprocess_data, etc
        return "agent"
    
# --- CONSTRUCTION DU GRAPH ---
def get_agent_app():
    memory = MemorySaver()
    workflow = StateGraph(AgentState)

    workflow.add_node("agent", agent_node)
    workflow.add_node("execute_tool", execute_tool_node)
    workflow.add_node("generate_final_response", generate_final_response_node)
    workflow.add_node("cleanup_state", cleanup_state_node)
    workflow.add_node("prepare_data_display", prepare_data_display_node) 
    workflow.add_node("prepare_chart_display", prepare_chart_display_node)
    workflow.add_node("prepare_news_display", prepare_news_display_node)
    workflow.add_node("prepare_profile_display", prepare_profile_display_node)
    workflow.add_node("handle_error", handle_error_node)

    workflow.set_entry_point("agent")

    workflow.add_conditional_edges("agent", router, {"execute_tool": "execute_tool", "handle_error": "handle_error", "__end__": END})
    workflow.add_conditional_edges(
        "execute_tool",
        router,
        {
            "agent": "agent", 
            "generate_final_response": "generate_final_response",
            "prepare_data_display": "prepare_data_display", 
            "prepare_chart_display": "prepare_chart_display",
            "prepare_news_display": "prepare_news_display", 
            "prepare_profile_display": "prepare_profile_display",
            "handle_error": "handle_error",
            "__end__": END
        }
    )

    workflow.add_edge("generate_final_response", "cleanup_state")
    workflow.add_edge("prepare_profile_display", "cleanup_state")
    workflow.add_edge("prepare_data_display", "cleanup_state")
    workflow.add_edge("prepare_chart_display", "cleanup_state")
    workflow.add_edge("prepare_news_display", "cleanup_state")
    workflow.add_edge("handle_error", "cleanup_state")
    workflow.add_edge("cleanup_state", END)

    app = workflow.compile(checkpointer=memory)

    try:
        graph = app.get_graph()
        image_bytes = graph.draw_mermaid_png()
        with open("agent_workflow.png", "wb") as f:
            f.write(image_bytes)
        
        print("\nVisualisation du graph sauvegard√©e dans le r√©pertoire en tant que agent_workflow.png \n")

    except Exception as e:
        print(f"\nJe n'ai pas pu g√©n√©rer la visualisation. Lancez 'pip install playwright' et 'playwright install'. Erreur: {e}\n")
    
    return app

app = get_agent_app()


# --- Cr√©e une animation du workflow ---
def generate_trace_animation_frames(thread_id: str):
    """
    R√©cup√®re une trace LangSmith et g√©n√®re une s√©rie d'images Graphviz au style moderne.
    """
    print(f"--- VISUALIZER: G√©n√©ration de l'animation pour : {thread_id} ---")
    try:
        style_config = {
            "graph": {
                "fontname": "Arial",
                "bgcolor": "transparent", # Fond transparent
                "rankdir": "TB", # Top-to-Bottom layout
            },
            "nodes": {
                "fontname": "Arial",
                "shape": "box", # Forme rectangulaire
                "style": "rounded,filled", # Bords arrondis et remplis
                "fillcolor": "#1C202D", # Couleur de fond des noeuds (th√®me sombre)
                "color": "#FAFAFA", # Couleur de la bordure
                "fontcolor": "#FAFAFA", # Couleur du texte
                "fontsize": "12", # Taille de police
            },
            "edges": {
                "color": "#6c757d", # Couleur gris doux pour les fl√®ches
                "arrowsize": "0.8",
            },
            "highlight": {
                "fillcolor": "#33FFBD", # Couleur orange pour le noeud actif (de chart_theme.py)
                "color": "#33FFBD", # Bordure blanche pour le noeud actif
                "fontcolor": "#000000", # Couleur noire pour le texte du noeud actif
                "edge_color": "#33FFBD", # Couleur orange pour la fl√®che active
            }
        }

        client = Client()
        all_runs = list(client.list_runs(
            project_name=os.environ.get("LANGCHAIN_PROJECT", "stella"),
            thread_id=thread_id,
        ))

        if not all_runs:
            print("--- VISUALIZER: Aucune ex√©cution trouv√©e pour cet ID de thread.")
            return []

        thread_run = next((r for r in all_runs if not r.parent_run_id), None)
        if not thread_run:
            print("--- VISUALIZER: Ex√©cution principale du thread introuvable.")
            return []

        trace_nodes_runs = sorted(
            [r for r in all_runs if r.parent_run_id == thread_run.id],
            key=lambda r: r.start_time
        )
        full_trace_path_names = [run.name for run in trace_nodes_runs]
        full_trace_path = ["__start__"] + full_trace_path_names + ["__end__"]

        if not trace_nodes_runs:
            print("--- VISUALIZER: Aucun noeud enfant (√©tape) trouv√© dans la trace.")
            return []

        print(f"--- VISUALIZER: Chemin d'ex√©cution trouv√© : {' -> '.join(full_trace_path)}")

        graph_json = app.get_graph().to_json()
        
        frames = []
        previous_node_in_trace = full_trace_path[0]
        
        node_labels_map = {}
        for node in graph_json["nodes"]:
            node_labels_map[node["id"]] = node["data"]["name"] if "data" in node and "name" in node["data"] else node["id"]


        for i, current_node_name_in_trace in enumerate(full_trace_path):
            # Attributs globaux pour le graphe
            graph_attrs = ' '.join([f'{k}="{v}"' for k, v in style_config["graph"].items()])
            node_attrs = ' '.join([f'{k}="{v}"' for k, v in style_config["nodes"].items()])
            edge_attrs = ' '.join([f'{k}="{v}"' for k, v in style_config["edges"].items()])

            dot_lines = [
                "digraph {",
                f"  graph [{graph_attrs}];",
                f"  node [{node_attrs}];",
                f"  edge [{edge_attrs}];",
            ]
            
            # Ajout des noeuds
            for node_in_graph_def in graph_json["nodes"]: 
                node_id_from_graph_def = node_in_graph_def["id"]
                display_label = node_labels_map[node_id_from_graph_def] 

                if node_id_from_graph_def == current_node_name_in_trace:
                    # Appliquer le libell√© personnalis√© pour 'execute_tool' UNIQUEMENT s'il est le n≈ìud mis en √©vidence
                    if node_id_from_graph_def == "execute_tool":
                        # Le Run object correspondant est trace_nodes_runs[i-1] car full_trace_path inclut __start__ au d√©but.
                        # On s'assure que l'index est valide pour trace_nodes_runs
                        if i > 0 and i <= len(trace_nodes_runs): 
                            specific_run = trace_nodes_runs[i-1] # Le Run object de Langsmith pour ce noeud 'execute_tool'
                            if specific_run.name == "execute_tool": # Double v√©rification que le nom correspond bien
                                if specific_run.inputs and 'messages' in specific_run.inputs:
                                    # Parcourir les messages d'entr√©e en sens inverse pour trouver le dernier AIMessage avec tool_calls
                                    for msg_dict in reversed(specific_run.inputs['messages']):
                                        # Les messages dans LangSmith Run.inputs sont des dictionnaires
                                        if isinstance(msg_dict, dict) and msg_dict.get('type') == 'ai' and msg_dict.get('tool_calls'):
                                            first_tool_call = msg_dict['tool_calls'][0] # On prend le premier tool_call (souvent le seul)
                                            tool_name = first_tool_call['name']
                                            tool_args = first_tool_call['args']
                                            
                                            args_str_parts = []
                                            for k, v in tool_args.items():
                                                if isinstance(v, str):
                                                    args_str_parts.append(f"{k}='{v}'")
                                                elif isinstance(v, list):
                                                    # G√®re les listes comme [item1, item2]
                                                    formatted_list = ", ".join([f"'{item}'" if isinstance(item, str) else str(item) for item in v])
                                                    args_str_parts.append(f"{k}=[{formatted_list}]")
                                                else:
                                                    # G√®re les nombres et autres types
                                                    args_str_parts.append(f"{k}={v}")
                                            
                                            args_display = ", ".join(args_str_parts)
                                            if args_display: # Ajoute les parenth√®ses seulement s'il y a des arguments
                                                display_label = f"execute_tool : {tool_name} ({args_display})"
                                            else:
                                                display_label = f"execute_tool : {tool_name}"
                                            break # On a trouv√© le bon message, on peut sortir de cette boucle interne
                        else:
                             print(f"Warning: Index de trace ({i}) hors limites ou n≈ìud sp√©cial pour {node_id_from_graph_def}")

                    # Appliquer le style de surbrillance avec texte en gras et couleur noire
                    highlight_attrs = ' '.join([f'{k}="{v}"' for k, v in style_config["highlight"].items() if 'edge' not in k])
                    dot_lines.append(f'  "{node_id_from_graph_def}" [label=<<B>{display_label}</B>>, {highlight_attrs}];')
                else:
                    # Appliquer le texte en gras pour tous les noeuds non surlign√©s aussi
                    dot_lines.append(f'  "{node_id_from_graph_def}" [label=<<B>{display_label}</B>>];') # Utilise le libell√© original pour les n≈ìuds non surlign√©s
            
            # Ajout des ar√™tes
            for edge in graph_json["edges"]:
                source = edge["source"]
                target = edge["target"]
                
                # Appliquer le style de surbrillance si c'est l'ar√™te active
                if source == previous_node_in_trace and target == current_node_name_in_trace:
                    dot_lines.append(f'  "{source}" -> "{target}" [color="{style_config["highlight"]["edge_color"]}", penwidth=2.5];')
                else:
                    dot_lines.append(f'  "{source}" -> "{target}";')
            
            dot_lines.append("}")
            modified_dot = "\n".join(dot_lines)
            
            g = graphviz.Source(modified_dot)
            png_bytes = g.pipe(format='png')

            step_description = f"Step {i+1}: Transition vers le noeud '{current_node_name_in_trace}'"
            if i == 0:
                step_description = "Step 1: D√©but de l'ex√©cution"
            elif i == len(full_trace_path) - 1:
                step_description = f"Step {i+1}: Fin de l'ex√©cution"
            frames.append((step_description, png_bytes))

            previous_node_in_trace = current_node_name_in_trace

        return frames

    except Exception as e:
        print(f"--- VISUALIZER: Erreur lors de la g√©n√©ration des frames: {e}")
        import traceback
        traceback.print_exc()
        return []

# --- Bloc test main ---
if __name__ == '__main__':
    def run_conversation(session_id: str, user_input: str):
        print(f"\n--- User: {user_input} ---")
        config = {"configurable": {"thread_id": session_id}}
        inputs = {"messages": [HumanMessage(content=user_input)]}
        final_message = None
        for event in app.stream(inputs, config=config, stream_mode="values"):
            final_message = event["messages"][-1]
        if final_message:
            print(f"\n--- R√©ponse finale de l'assistant ---\n{final_message.content}")
            if hasattr(final_message, 'image_base64'):
                print("\n[L'image a √©t√© g√©n√©r√©e et ajout√©e au message final]")

    conversation_id = f"test_session_{uuid.uuid4()}"
    run_conversation(conversation_id, "Qui sont les cr√©ateurs du projet ?")
